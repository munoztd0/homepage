[
  {
    "objectID": "services.html",
    "href": "services.html",
    "title": "Services",
    "section": "",
    "text": "Services\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n Data Visualization\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n Data Science and Analysis\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n Data Engineering\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n Teaching & Training\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/2023-04-Deploy-your-R-code/index.html",
    "href": "talks/2023-04-Deploy-your-R-code/index.html",
    "title": "Deploy Your R Code!",
    "section": "",
    "text": "Deploy Your R Code!\n\n\n\n\n\nFull Slides\nPresentation Recording"
  },
  {
    "objectID": "talks/learning_from_data/index.html",
    "href": "talks/learning_from_data/index.html",
    "title": "Learning From Data: A Podcast of WeData‚Äôs Story now on Spotify üéß",
    "section": "",
    "text": "Thrilled to share that Vestin Hategekimana and I are featured in the latest episode of ‚ÄúLearning from Data‚Äù podcast! üöÄ Join us as we discuss WeData, our university association dedicated to sharing our passion for data science and computer science through an interdisciplinary approach. üåê\nEpisode Duration: 1 hr 14 min üïí Listen in now on Spotify to gain valuable insights into the world of data science! üéß\n\n\nWeData isn‚Äôt just an association; it‚Äôs a vibrant hub for data enthusiasts, a collaborative platform, and a driving force for innovation. Through a myriad of workshops, events, and knowledge-sharing initiatives, we empower individuals and catalyze advancements in data science and computer science.\n\n\n\nDuring the interview, we uncovered our backgrounds, shared pivotal moments that ignited our passion for data science, and elucidated why WeData became our chosen platform. From exploring migration and integration to delving into statistics and text mining, we explored the diverse facets of data science that fuel our curiosity and propel our endeavors.\nListen to the full episode here."
  },
  {
    "objectID": "talks/learning_from_data/index.html#about-wedata",
    "href": "talks/learning_from_data/index.html#about-wedata",
    "title": "Learning From Data: A Podcast of WeData‚Äôs Story now on Spotify üéß",
    "section": "",
    "text": "WeData isn‚Äôt just an association; it‚Äôs a vibrant hub for data enthusiasts, a collaborative platform, and a driving force for innovation. Through a myriad of workshops, events, and knowledge-sharing initiatives, we empower individuals and catalyze advancements in data science and computer science."
  },
  {
    "objectID": "talks/learning_from_data/index.html#the-interview",
    "href": "talks/learning_from_data/index.html#the-interview",
    "title": "Learning From Data: A Podcast of WeData‚Äôs Story now on Spotify üéß",
    "section": "",
    "text": "During the interview, we uncovered our backgrounds, shared pivotal moments that ignited our passion for data science, and elucidated why WeData became our chosen platform. From exploring migration and integration to delving into statistics and text mining, we explored the diverse facets of data science that fuel our curiosity and propel our endeavors.\nListen to the full episode here."
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Talks, Podcasts & Worshops",
    "section": "",
    "text": "Talks, Podcasts & Worshops\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nLearning From Data: A Podcast of WeData‚Äôs Story now on Spotify üéß\n\n\n\n\n\n\n\nSpotify\n\n\nPodcast\n\n\nData Science\n\n\nAssociation\n\n\n\n\n\n\n\n\n\n\n\nApr 3, 2024\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nDeploy Your R Code!\n\n\n\n\n\n\n\nTalk\n\n\nThoughts\n\n\nWeb\n\n\nR\n\n\nImplementing an idea\n\n\nDevOps\n\n\n\n\n\n\n\n\n\n\n\nApr 4, 2023\n\n\nDavid Munoz Tord\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/Data_manip_Fundamental/index.html",
    "href": "blog/Data_manip_Fundamental/index.html",
    "title": "Data Manipulation with R",
    "section": "",
    "text": "By David Munoz Tord\nGoal: Learn more about data manipulation: how to pivot, join and filter data using {dplyr} and {tidyr} packages.\nOpen it full\nNote: All in english"
  },
  {
    "objectID": "blog/Data_Viz_Fundamentals/index.html",
    "href": "blog/Data_Viz_Fundamentals/index.html",
    "title": "Data Viz Fundamentals with R",
    "section": "",
    "text": "By David Munoz Tord\nGoal: Go over the basics of data visualization with R and learn more advanced concepts using the ggplot package.\nNote: All is in english\nOpen it full"
  },
  {
    "objectID": "blog/R-Lunches/index.html",
    "href": "blog/R-Lunches/index.html",
    "title": "R Lunches in university of Geneva",
    "section": "",
    "text": "By David Munoz Tord\nR lunches are multidisciplinary meetings on R at UniMail.\nWe finished this semester R Lunches but you can still find the video links if you missed one!\nRead more about it"
  },
  {
    "objectID": "blog/Data_explor_Fundamentals/index.html",
    "href": "blog/Data_explor_Fundamentals/index.html",
    "title": "Data Exploration with R",
    "section": "",
    "text": "By David Munoz Tord\nGoal: Learn about data exploration and familiarize yourself with some of the basic functions of the tidyverse.\nOpen it full\nNote: All in english"
  },
  {
    "objectID": "blog/llm2/index.html",
    "href": "blog/llm2/index.html",
    "title": "Your first chat bot with python!",
    "section": "",
    "text": "By David Munoz Tord\nGoal: Learn about language models and familiarize yourself with some of the basic functions of the {languagemodels} to create your own chat bot.\n{languagemodels} is a python module designed to be as simple as possible for learners and educators exploring how large language models intersect with modern software development. The interfaces to this package are all simple functions using standard types. The complexity of large language models is hidden from view while providing free local inference using light-weight, open models. All included models are free for educational use, no API keys are required, and all inference is performed locally by default.\nRead more about it\n\nimport languagemodels as lm\n\n\nlm.do(\"What color is the sky?\")\n\n'The color of the sky is blue.'\n\n\nFetching 6 files:   0%|          | 0/6 [00:00&lt;?, ?it/s]\nFetching 6 files: 100%|##########| 6/6 [00:00&lt;00:00, 8053.06it/s]\n\n\n\nTo easy, let‚Äôs try something a bit harder\n\nlm.do(\"If I have 7 apples then eat 5, how many apples do I have?\")\n\n'You have 8 apples.'\n\n\nAouch‚Ä¶\nIndeed the model performance is quite low because the models used by this package are 1000x smaller than the largest models in use today. They are useful as learning tools, but if you are expecting ChatGPT or similar performance, you will be very disappointed‚Ä¶\nThe base model should work on any system with 512MB of memory, but this memory limit can be increased. Setting this value higher will require more memory and generate results more slowly, but the results should be superior.\n\n#lm.set_max_ram('4gb')\n\n\nlm.do(\"If I have 7 apples then eat 5, how many apples do I have?\")\n\n'You have 8 apples.'\n\n\nYeah, here we go little (4gb) buddy!\n\nNow that we got the basics, let‚Äôs play with it! You can change the prompt like such\n\nlm.chat('''\n     System: Respond as a physics professor.\n\n     User: What is relativity?\n\n     Assistant:\n     ''')\n\n'Relativity is the theory of relativity, which describes how time and space are relative to each other.'\n\n\n\n\nlm.complete(\"She hid in her room until\")\n\n' the night sky turned blue.'\n\n\n\n\nlm.get_wiki(\"Physics\")\n\n'Physics is the natural science of matter, involving the study of matter, its fundamental constituents, its motion and behavior through space and time, and the related entities of energy and force. Physics is one of the most fundamental scientific disciplines, with its main goal being to understand how the universe behaves. A scientist who specializes in the field of physics is called a physicist.\\n\\nPhysics is one of the oldest academic disciplines and, through its inclusion of astronomy, perhaps the oldest. Over much of the past two millennia, physics, chemistry, biology, and certain branches of mathematics were a part of natural philosophy, but during the Scientific Revolution in the 17th century these natural sciences emerged as unique research endeavors in their own right. Physics intersects with many interdisciplinary areas of research, such as biophysics and quantum chemistry, and the boundaries of physics are not rigidly defined. New ideas in physics often explain the fundamental mechanisms studied by other sciences and suggest new avenues of research in these and other academic disciplines such as mathematics and philosophy.\\n\\nAdvances in physics often enable new technologies. For example, advances in the understanding of electromagnetism, solid-state physics, and nuclear physics led directly to the development of new products that have dramatically transformed modern-day society, such as television, computers, domestic appliances, and nuclear weapons; advances in thermodynamics led to the development of industrialization; and advances in mechanics inspired the development of calculus.'"
  },
  {
    "objectID": "blog/Live/index.html",
    "href": "blog/Live/index.html",
    "title": "We-Data Live on YouTube",
    "section": "",
    "text": "By David Munoz Tord, Fabrice Hategekimana and Vestin Hategekimana\nLive of December 29 edited in which we present in more detail WeData, its functioning and its future.\nNote: video in french, ask in comments for subtitle in your language\nVideo link"
  },
  {
    "objectID": "projects/biodiverRsity/index.html",
    "href": "projects/biodiverRsity/index.html",
    "title": "Biodiversity Bonanza: Crafting a Shiny Species Spotter!",
    "section": "",
    "text": "Ahoy, fellow code adventurers and nature enthusiasts! Today, we‚Äôre diving headfirst into the wild world of biodiversity data. Grab your digital binoculars, because we‚Äôre about to embark on a thrilling journey to build a Shiny app that‚Äôll make David Attenborough jealous!\n\n\nPicture this: You‚Äôre a wildlife researcher with a mountain of data and a burning question - ‚ÄúHow have animal sightings changed over time?‚Äù Fear not! We‚Äôre crafting a tool so snazzy, it‚Äôll turn that data mountain into a molehill faster than you can say ‚ÄúMarmota marmota‚Äù!\n\n\n\n\nThe Shapeshifting Maps: Different ways to visualize you data and even query the actual images.\nThe All-Seeing Search Bar: A selectize input so smart, it‚Äôll find your species faster than a cheetah chasing its lunch.\nThe Time-Traveling Timeline: A plot that‚Äôll zip through years of animal sightings quicker than you can say ‚ÄúGreat Scott!‚Äù\n\nLet‚Äôs peek under the hood of our biodiversity hotrod‚Ä¶\nSee the full code on GitHub"
  },
  {
    "objectID": "projects/biodiverRsity/index.html#welcome-to-the-forest-of-data",
    "href": "projects/biodiverRsity/index.html#welcome-to-the-forest-of-data",
    "title": "Biodiversity Bonanza: Crafting a Shiny Species Spotter!",
    "section": "",
    "text": "Ahoy, fellow code adventurers and nature enthusiasts! Today, we‚Äôre diving headfirst into the wild world of biodiversity data. Grab your digital binoculars, because we‚Äôre about to embark on a thrilling journey to build a Shiny app that‚Äôll make David Attenborough jealous!\n\n\nPicture this: You‚Äôre a wildlife researcher with a mountain of data and a burning question - ‚ÄúHow have animal sightings changed over time?‚Äù Fear not! We‚Äôre crafting a tool so snazzy, it‚Äôll turn that data mountain into a molehill faster than you can say ‚ÄúMarmota marmota‚Äù!\n\n\n\n\nThe Shapeshifting Maps: Different ways to visualize you data and even query the actual images.\nThe All-Seeing Search Bar: A selectize input so smart, it‚Äôll find your species faster than a cheetah chasing its lunch.\nThe Time-Traveling Timeline: A plot that‚Äôll zip through years of animal sightings quicker than you can say ‚ÄúGreat Scott!‚Äù\n\nLet‚Äôs peek under the hood of our biodiversity hotrod‚Ä¶\nSee the full code on GitHub"
  },
  {
    "objectID": "projects/biodiverRsity/index.html#the-star-players-in-our-data-drama",
    "href": "projects/biodiverRsity/index.html#the-star-players-in-our-data-drama",
    "title": "Biodiversity Bonanza: Crafting a Shiny Species Spotter!",
    "section": "üé≠ The Star Players in Our Data Drama",
    "text": "üé≠ The Star Players in Our Data Drama\n\nüó∫Ô∏è The Cartographer‚Äôs Delight: Our Magical Map Module\nHold onto your compasses, explorers! We‚Äôre about to unfold a map so interactive!\n\nmap_server &lt;- function(id, selected_species_data, use_heatmap, config) {\n  moduleServer(id, function(input, output, session) {\n    output$map &lt;- renderLeaflet({\n      leaflet() |&gt;\n        addTiles() |&gt;\n        setView(lng = config$MAP_CENTER_LNG, lat = config$MAP_CENTER_LAT, zoom = config$MAP_ZOOM)\n    })\n    \n    observe({\n      data &lt;- selected_species_data()\n      use_heatmap &lt;- use_heatmap()\n      \n      if (!is.null(data) && nrow(data) &gt; 0) {\n        valid_data &lt;- data[!is.na(data$latitudeDecimal) & !is.na(data$longitudeDecimal), ]\n        if (nrow(valid_data) &gt; 0) {\n          map &lt;- leafletProxy(\"map\") |&gt;\n            clearMarkerClusters() |&gt;\n            clearHeatmap()\n          \n          if (use_heatmap) {\n            map |&gt; addHeatmap(\n              data = valid_data,\n              lng = ~longitudeDecimal, \n              lat = ~latitudeDecimal,\n              blur = config$HEATMAP_BLUR, \n              max = config$HEATMAP_MAX, \n              radius = config$HEATMAP_RADIUS\n            )\n          } else {\n\n            \n            map |&gt; addMarkers(\n              data = valid_data,\n              lng = ~longitudeDecimal, \n              lat = ~latitudeDecimal,\n              popup = ~paste(\n                \"&lt;strong&gt;\", scientificName, \"&lt;/strong&gt;&lt;br&gt;\",\n                \"Date: \", eventDate, \"&lt;br&gt;\",\n                ifelse(!is.na(accessURI), \n                       paste0(\"&lt;img src='\", accessURI, \"' width='100'&gt;&lt;br&gt;\",\n                              \"Image by: \", creator, \"&lt;br&gt;\",\n                              \"License: \", multimedia_license),\n                       \"No image available\")\n              ),\n              clusterOptions = markerClusterOptions(\n                showCoverageOnHover = FALSE,\n                zoomToBoundsOnClick = TRUE,\n                spiderfyOnMaxZoom = TRUE,\n                removeOutsideVisibleBounds = TRUE,\n                disableClusteringAtZoom = config$CLUSTER_ZOOM_DISABLE\n              )\n            )\n          }\n        }\n      }\n    })\n  })\n}\n\n\nüåã Features That‚Äôll Make You Erupt with Joy\nShapeshifting Views: Toggle between marker clusters and heatmaps faster than a chameleon changes colors! Popup Bonanza: Click a marker and BOOM! Species info, dates, and even glamour shots of our animal celebs! Cluster Parties: Watch as our markers gather in cliques like teenagers at a mall. Zoom in to break up the party!\n\n\nüé≠ The Great Heatmap vs.¬†Marker Debate\nOur map is like a secret agent with two disguises:\nHeatmap Mode: Transform your map into a thermal vision of biodiversity hotspots. It‚Äôs like predator vision, but for science! Marker Mode: Unleash a confetti of markers, each hiding a treasure trove of information. It‚Äôs Where‚Äôs Waldo, but for species!\n\n\n\nüî† The Search Sorcerer\nThis little wizard conjures up species names faster than you can type ‚Äúplatypus‚Äù. It‚Äôs like Google for critters, but cooler!\n\nsearch_server &lt;- function(id, biodiversity_data) {\n  # Server sorcery unfolds\n\n  search_server &lt;- function(id, biodiversity_data) {\n  moduleServer(id, function(input, output, session) {\n    # Prepare search data\n    search_data &lt;- biodiversity_data |&gt;\n      select(scientificName, vernacularName) |&gt;\n      distinct() |&gt;\n      mutate(search_term = paste(scientificName, vernacularName, sep = \" - \")) |&gt;\n      arrange(scientificName)\n\n    updateSelectizeInput(session, \"species_search\", \n                         choices = setNames(search_data$scientificName, search_data$search_term),\n                         selected = \"Marmota marmota\",\n                         options = list(\n                           placeholder = 'Type to search species',\n                           maxOptions = 10000,  # Increase this number\n                           searchField = c('value', 'label'),\n                           render = I(\"{\n                             option: function(item, escape) {\n                               return '&lt;div&gt;' + escape(item.label) + '&lt;/div&gt;';\n                             }\n                           }\")\n                         ))\n    \n    return(reactive({ input$species_search }))\n  })\n}\n\n}\n\n\n\nüìä The Timeline Tamer\nWatch years of animal sightings dance before your eyes! This module turns boring numbers into a visual feast that would make any statistician swoon.\n\ntimeline_server &lt;- function(id, selected_data) {\n  # Data wrangling extravaganza\n    timeline_server &lt;- function(id, selected_data) {\n  moduleServer(id, function(input, output, session) {\n    output$timeline &lt;- renderPlotly({\n      data &lt;- selected_data()\n      if (!is.null(data) && nrow(data) &gt; 0) {\n        # Aggregate data by year\n        yearly_counts &lt;- data |&gt;\n          mutate(year = lubridate::year(eventDate)) |&gt;\n          count(year)\n        \n        # Create the base plot\n        p &lt;- plot_ly() |&gt;\n          add_trace(data = yearly_counts, x = ~year, y = ~n, type = \"bar\", \n                    name = \"Observations\", marker = list(color = \"#165098\"))\n        \n        # Check if data spans more than one year\n        if (length(unique(yearly_counts$year)) &gt; 1) {\n          # Calculate smooth regression\n          loess_fit &lt;- loess(n ~ year, data = yearly_counts, span = 0.75)\n          smoothed_data &lt;- data.frame(\n            year = seq(min(yearly_counts$year), max(yearly_counts$year), length.out = 100)\n          )\n          smoothed_data$n &lt;- predict(loess_fit, newdata = smoothed_data)\n          \n          # Add trend line to the plot\n          p &lt;- p |&gt;\n            add_trace(data = smoothed_data, x = ~year, y = ~n, type = \"scatter\", mode = \"lines\",\n                      name = \"Trend\", line = list(color = \"#e94560\", width = 3))\n        }\n        \n        # Layout (same as before)\n        p &lt;- p |&gt;\n          layout(\n            title = list(text = \"Observations Over Time\", font = list(size = 24, color = \"#ffffff\")),\n            xaxis = list(title = \"Year\", titlefont = list(size = 18, color = \"#a9a9a9\"),\n                         tickfont = list(size = 14, color = \"#a9a9a9\"),\n                         tickformat = \"d\"),\n            yaxis = list(title = \"Number of Observations\", titlefont = list(size = 18, color = \"#a9a9a9\"),\n                         tickfont = list(size = 14, color = \"#a9a9a9\")),\n            legend = list(font = list(color = \"#a9a9a9\")),\n            paper_bgcolor = \"#1a1a2e\",\n            plot_bgcolor = \"#16213e\",\n            margin = list(l = 80, r = 40, b = 60, t = 80, pad = 4),\n            barmode = \"overlay\"\n          )\n        \n        p\n      }\n    })\n  })\n}\n  \n}\n\n\nüé¢ Thrills, Spills, and Coding Chills\nBuilding this cartographic app was no walk in the park. We faced:\nThe Coordinate Conundrum: We wrangled latitude and longitude like a cowboy at a rodeo. Yee-haw, data points! The Cluster Kerfuffle: We taught our markers to play nice and form orderly groups. It‚Äôs like herding cats, but with GPS! The Heatmap Hustle: We turned data density into a visual feast. It‚Äôs hotter than a jalape√±o‚Ä¶ visually speaking! The Great Data Deluge: We tamed a tsunami of biodiversity data with our bare hands (and some nifty dplyr magic)! The Single-Year Showdown: We outsmarted the dreaded ‚Äúspan is too small‚Äù error. Take that, statistics gremlins!\n\n\nüöÄ Launching Our Creation into the Wild\n\n::\nrsconnect::deployApp()\n\n\n\nüîÆ The Future is Wild\nWith our map module, you can:\nZoom from continent to backyard faster than you can say ‚Äúbiodiversity hotspot‚Äù Uncover species hangout spots like a nature paparazzi Play ‚ÄúSix Degrees of Species Separation‚Äù with our interconnected data points Search for species faster than a peregrine falcon in a nosedive Watch observation trends unfold like a time-lapse of a blooming rainforest Impress your scientist friends at parties (because who doesn‚Äôt talk about R at parties?)\nBut wait, there‚Äôs more! Imagine if this app could:\nTime-travel through species migrations (DeLorean not included) Predict future animal meetup spots (like Tinder, but for wildlife) Generate 3D holograms of habitats (Star Wars, eat your heart out!) Map species like a GPS for the animal kingdom Predict animal trends better than a psychic octopus Generate David Attenborough-style narration for each species (okay, we‚Äôre dreaming big here)\nSo there you have it, folks! Our map module isn‚Äôt just a feature, it‚Äôs a portal to adventure. It‚Äôs not just showing where animals have been spotted; it‚Äôs inviting you to become the next great explorer from the comfort of your laptop. Remember, in the world of biodiversity data, X marks the spot‚Ä¶ and we‚Äôve got all the Xs you could ever want! Now go forth and map your way to glory!\n\n\nüéâ The Grand Finale\nThere you have it, folks!\n\nWe‚Äôve just built the Swiss Army knife of biodiversity visualization. It slices, it dices, it even makes julienne fries! (Okay, maybe not that last part.) Remember, in the jungle of data, the prepared coder is king. So go forth, explore, and may your plots be ever in your favor!\nOpen it full\n\n\nNotes\nP.S. No animals were harmed in the making of this Shiny app, but several keyboards were tickled mercilessly."
  },
  {
    "objectID": "projects/DeepLearning/index.html",
    "href": "projects/DeepLearning/index.html",
    "title": "Deep Reinforcement Learning with PyTorch (Super Mario Bros)",
    "section": "",
    "text": "Reinforcement Learning with PyTorch (Super Mario Bros)\nHere is a project I worked on to train AI agents to play and solve games using reinforcement learning. The project is based on the Super Mario Bros game, and the AI agents are trained using the Proximal Policy Optimization (PPO) algorithm. The agents are implemented using the PyTorch library, and the game environment is provided by the OpenAI Gym library . The project also includes a custom implementation of the game environment, which is based on the Super Mario Bros game for the Nintendo Entertainment System (NES). The game environment is implemented using the FCEUX emulator, and the game is controlled using the Python library PyAutoGUI.\n\nI also used TensorBoard to visualize and evaluate the quality metrics of the model.\n\n Check out the project on GitHub."
  },
  {
    "objectID": "projects/WeData/index.html",
    "href": "projects/WeData/index.html",
    "title": "We Data Association",
    "section": "",
    "text": "We Data Association\nWe are an association of the University of Geneva that aims to share its passion for data science and computer science. We have a strong interest in statistics and computational methods. Initially, the association‚Äôs target audience was people in the social sciences but we quickly expanded into other fields of research.\nMore concretely, the association aims to achieve its objectives by creating freely-accessible educational content on its platforms in a variety of forms: YouTube videos, blog posts, exercises, etc. The association co-organizes the R-Lunches, a series of events related to R in which various speakers present topics related to the R language. The association tries to keep abreast of and participate as often as possible in digital initiatives at the University of Geneva.\n\n Check out the project on our website."
  },
  {
    "objectID": "projects/LeekWars/index.html",
    "href": "projects/LeekWars/index.html",
    "title": "Leek Wars: Training AI agents to beat each other in a game",
    "section": "",
    "text": "Leek Wars: Training AI agents to compete in a game\nLeek Wars is a multiplayer Artifical Intelligence programming game. The language of Leek Wars is LeekScript. Follow my best leek @leakit22 ! I remain in the top 300 for the time being.\n\n Check out the project on GitHub."
  },
  {
    "objectID": "projects/GameOfLife/index.html",
    "href": "projects/GameOfLife/index.html",
    "title": "Cellular Automata: Conway‚Äôs Game of Life",
    "section": "",
    "text": "Conway‚Äôs Game Of Life implemented in Python\nConway‚Äôs Game of Life is a cellular automaton devised by the British mathematician John Horton Conway in 1970. The game is a zero-player game, meaning that its evolution is determined by its initial state, requiring no further input. One interacts with the Game of Life by creating an initial configuration and observing how it evolves.\nA given cell (i, j) in the simulation is accessed on a grid [i][j], where i and j are the row and column indices, respectively. The value of a given cell at a given instant of time depends on the state of its neighbors at the previous time step.\nConway‚Äôs Game of Life has four rules:\n\nIf a cell is ON and has fewer than two neighbors that are ON, it turns OFF.\nIf a cell is ON and has either two or three neighbors that are ON, it remains ON.\nIf a cell is ON and has more than three neighbors that are ON, it turns OFF.\nIf a cell is OFF and has exactly three neighbors that are ON, it turns ON.\n\nThe bulk of the graphical implementation was made using PyGame.\n\nCheck out the project on GitHub."
  },
  {
    "objectID": "projects/2022-12-echarts4r/index.html",
    "href": "projects/2022-12-echarts4r/index.html",
    "title": "Echarts4r",
    "section": "",
    "text": "Easy and beautiful interactive dataviz with Echarts4r!\nThis R package is a wrapper of the ECharts library. It provides a set of functions to generate interactive charts in R.\n\nlibrary(dplyr)\nlibrary(echarts4r)\nlibrary(lubridate)\n\n# Plot 1\nmtcars |&gt;\n  e_charts(cyl) |&gt; \n  e_boxplot(disp, colorBy=\"data\",) |&gt;\n  e_boxplot(hp, colorBy=\"data\",) |&gt;\n  e_boxplot(mpg, colorBy=\"data\",) |&gt;\n  e_tooltip(trigger = \"axis\") |&gt;\n  e_title(\"Descriptive Stats on mtcars Data\") |&gt;\n  e_toolbox_feature(feature = \"saveAsImage\")  # add the download button!\n\n\n\n\n# Plot 2\nlakers |&gt;           \n  mutate(date = lubridate::ymd(date)) |&gt;\n  mutate(points = points+runif(n=34624, min=-0.5, max=0.5) ) |&gt;\n  group_by(date) |&gt;\n  summarise(points2 = sum(points),\n            min= points2 - (50 +min(points)),\n            max=points2 + (50+max(points)) ) |&gt; \n  e_charts(date) |&gt;\n  e_line(points2) |&gt;\n  e_band2(min, max, color = \"lemonchiffon\") |&gt;\n  e_tooltip(trigger = \"axis\") |&gt;\n  e_title(\"Lakers Timeseries Data\") |&gt;\n  e_toolbox_feature(feature = \"saveAsImage\")  # add the download button!\n\n\n\n\n# Plot 3\nstarwars |&gt;\n  e_charts(mass) |&gt;\n  e_scatter(height, bind = name, symbol_size = 5, legend =F) |&gt;\n  e_datazoom() |&gt;\n  e_tooltip(\n    formatter = htmlwidgets::JS(\"\n      function(params){\n        return('&lt;strong&gt;' + params.name + \n                '&lt;/strong&gt;&lt;br /&gt;mass: ' + params.value[0] + \n                '&lt;br /&gt;height: ' + params.value[1]) \n                }\n    \")) |&gt; # little JS formatter to make it pretty\n  e_title(\"Starwars Outlier Data\") |&gt;\n  e_toolbox_feature(feature = \"saveAsImage\")  # add the download button!\n\n\n\n\n\n \n\n\n\n\n Full Screen\n\n\n\n\nDescription\n\n\n\nHighlights of this package:  - Provide functions to generate interactive charts in R. - The package is built on top of the ECharts library, which is a powerful library for data visualization. - The package provides a set of functions that can be used to generate charts with ECharts. - The package is still under development. More features will be added in the future. - The package is open source.\n Features of the package: \n\nProvides more than 20 chart types available out of the box, along with a dozen components, and each of them can be arbitrarily combined to use.\nHas a powerful rendering engine that allows you to easily switch between Canvas and SVG rendering. Progressive rendering and stream loading make it possible to render 10 million data in realtime.\nOffers professional data analysis through datasets, which support data transforms like filtering, clustering, and regression to help analyze multi-dimensional analysis of the same data.\nHas an elegant visual design that follows visualization principles and supports responsive design. Flexible configurations make it easy to customize.\nHas a healthy community that ensures the healthy development of the project and contributes a wealth of third-party extensions.\nIs accessibility-friendly with automatically generated chart descriptions and decal patterns that help users with disabilities understand the content and the stories behind the charts.\n\n\nYou can check the project on Github."
  },
  {
    "objectID": "projects/MonitoR/index.html",
    "href": "projects/MonitoR/index.html",
    "title": "Shiny Usage Monitor",
    "section": "",
    "text": "Know thyself\nKeeping track of the number of users on your Shiny Server is helpful for several reasons:\n\n Identifies low-traffic periods (best times to push updates or restart the server).\n Tells you if you need to pay more attention to scaling your apps (i.e.¬†adjust server size, optimize slow apps).\n Shows which apps are most popular.\n Basic architecture.\n Deploy Shiny Server Open Source with one or more apps.\n Continuously check your server‚Äôs logs and save off data on the number of users on each app (check_server.R plus a cronjob).\n Use Shiny to display the data over time.\n\n\n\nCheck out the project on GitHub."
  },
  {
    "objectID": "projects/DbVieweR/index.html",
    "href": "projects/DbVieweR/index.html",
    "title": "DbVieweR",
    "section": "",
    "text": "DbVieweR an R package for database management\nDbVieweR is a Shiny app that simulates a database management system, featuring functions like login/logout, save/create/delete tables, and add/rename columns.\n\n\n\n\n Demo \n\n\nDescription\n\n\n\nHighlights of this app:  - Back-end database: Utilizes SQLite or PostgreSQL for storing dummy data. - Authorization: Incorporates the shinyauthr package to add an authentication layer to the app.  Features of the app:  - Save tables: Store sales summary tables in the database. - Update existing tables: Rename tables or columns. - Create new tables: Customize table and column names, with options for integer, float, varchar(255), and boolean columns. - Create entries: Add entries to tables with customizable column types. - Delete tables: Accessible only with specific authorization. - Robustness: Defense mechanism prevents duplicates, invalid expressions, and conflicts with SQL keywords.  Check out the project on GitHub."
  },
  {
    "objectID": "projects/RoadKills/index.html",
    "href": "projects/RoadKills/index.html",
    "title": "Cycling Through Data: ProVelo‚Äôs Innovative Road Safety Dashboard",
    "section": "",
    "text": "Attention cycling enthusiasts and safety advocates! ProVelo and I are excited to unveil our latest project - an interactive dashboard that‚Äôs set to transform how we understand road safety in Geneva. Say goodbye to static reports and hello to a dynamic, data-driven experience that puts the power of analysis at your fingertips.\nOur team has developed a state-of-the-art Shiny dashboard that brings accident data to life. It‚Äôs not just a tool; it‚Äôs a digital Swiss Army knife for road safety analysis. Whether you‚Äôre a policymaker, a concerned citizen, or a data enthusiast, this dashboard offers something for everyone.\n\nOpen it full"
  },
  {
    "objectID": "projects/RoadKills/index.html#pedaling-towards-a-safer-city",
    "href": "projects/RoadKills/index.html#pedaling-towards-a-safer-city",
    "title": "Cycling Through Data: ProVelo‚Äôs Innovative Road Safety Dashboard",
    "section": "",
    "text": "Attention cycling enthusiasts and safety advocates! ProVelo and I are excited to unveil our latest project - an interactive dashboard that‚Äôs set to transform how we understand road safety in Geneva. Say goodbye to static reports and hello to a dynamic, data-driven experience that puts the power of analysis at your fingertips.\nOur team has developed a state-of-the-art Shiny dashboard that brings accident data to life. It‚Äôs not just a tool; it‚Äôs a digital Swiss Army knife for road safety analysis. Whether you‚Äôre a policymaker, a concerned citizen, or a data enthusiast, this dashboard offers something for everyone.\n\nOpen it full"
  },
  {
    "objectID": "projects/RoadKills/index.html#data-source-sitgs-traffic-accident-dataset",
    "href": "projects/RoadKills/index.html#data-source-sitgs-traffic-accident-dataset",
    "title": "Cycling Through Data: ProVelo‚Äôs Innovative Road Safety Dashboard",
    "section": "Data Source: SITG‚Äôs Traffic Accident Dataset",
    "text": "Data Source: SITG‚Äôs Traffic Accident Dataset\nOur dashboard is powered by comprehensive data from the SITG (Geneva Territory Information System) website. We‚Äôre using the ‚ÄúTRAFFIC ACCIDENTS (SINCE 2010)‚Äù dataset, available at ge.ch/sitg/fiche/8139.\nThis dataset is derived from the MISTRA VUGIS application of the Federal Roads Office (OFROU), a tool for visualizing and geographically analyzing traffic accidents recorded by police officers. The data is exported annually and includes accidents that occurred from 2010 up to December 31, 2023, in the Canton of Geneva. However, our dashboard focuses on the most recent three years of data for the most current insights.\n\nFeatures That Will Shift Your Perspective\n\nInteractive Map: The heart of our dashboard is a dynamic map that transforms Geneva into a canvas of road safety insights. Watch as accident hotspots come into focus with just a few clicks.\nFlexible Filtering: Drill down into specific scenarios with our comprehensive filtering options. From weather conditions to vehicle types, you‚Äôre in control of the data you see.\nVariable Variety: Choose from a range of variables to display, covering everything from standard bicycles to e-bikes and pedestrian incidents.\nReal-Time Analytics: Watch as totals update instantly based on your selections. It‚Äôs like having a data analyst working overtime, just for you.\nData on Demand: Download filtered datasets for deeper analysis. Your next research project or policy proposal is just a click away.\nClear Explanations: We‚Äôve included a handy glossary to ensure everyone speaks the same language when it comes to road safety data."
  },
  {
    "objectID": "projects/RoadKills/index.html#under-the-hood",
    "href": "projects/RoadKills/index.html#under-the-hood",
    "title": "Cycling Through Data: ProVelo‚Äôs Innovative Road Safety Dashboard",
    "section": "Under the Hood",
    "text": "Under the Hood\nFor those curious about the technical details, our dashboard is powered by:\n\nShiny: Providing a reactive and responsive user experience\nLeaflet: Offering smooth and intuitive mapping capabilities\ndplyr: Enabling efficient data manipulation behind the scenes\nshinydashboard: Wrapping it all in a sleek, professional interface\n\nSee the full code on GitHub"
  },
  {
    "objectID": "projects/RoadKills/index.html#why-this-matters",
    "href": "projects/RoadKills/index.html#why-this-matters",
    "title": "Cycling Through Data: ProVelo‚Äôs Innovative Road Safety Dashboard",
    "section": "Why This Matters",
    "text": "Why This Matters\nThis isn‚Äôt just another data visualization tool - it‚Äôs a potential game-changer for Geneva‚Äôs streets:\n\nHotspot Identification: Quickly pinpoint areas with high accident rates, informing targeted safety interventions.\nPattern Recognition: Uncover hidden trends in accident data that could lead to smarter urban planning and policy decisions.\nInformed Decision Making: Equip policymakers and urban planners with the insights they need to make data-driven decisions about cycling infrastructure.\nPublic Awareness: By making this data accessible, we‚Äôre empowering citizens to better understand and engage with road safety issues in their community."
  },
  {
    "objectID": "projects/RoadKills/index.html#looking-ahead",
    "href": "projects/RoadKills/index.html#looking-ahead",
    "title": "Cycling Through Data: ProVelo‚Äôs Innovative Road Safety Dashboard",
    "section": "Looking Ahead",
    "text": "Looking Ahead\nWhile we‚Äôre excited about the current capabilities of our dashboard, we‚Äôre already thinking about future enhancements. Potential additions include trend analysis over time, predictive modeling for risk assessment, and integration with other urban data sources."
  },
  {
    "objectID": "projects/RoadKills/index.html#join-the-ride",
    "href": "projects/RoadKills/index.html#join-the-ride",
    "title": "Cycling Through Data: ProVelo‚Äôs Innovative Road Safety Dashboard",
    "section": "Join the Ride",
    "text": "Join the Ride\nWe invite you to explore this new tool and join us in our mission to make Geneva‚Äôs roads safer for everyone. Whether you‚Äôre a casual cyclist, a dedicated commuter, or a city planner, your insights and feedback can help shape the future of cycling safety in our city.\nTogether, let‚Äôs pedal towards a safer, more data-informed future for all road users in Geneva! üö¥"
  },
  {
    "objectID": "projects/hBDM/index.html",
    "href": "projects/hBDM/index.html",
    "title": "Hierarchical Bayesian Modeling",
    "section": "",
    "text": "Hierarchical Bayesian modeling of Decision-Making tasks\nI collaborated on the Hierarchical Bayesian modeling of Decision-Making tasks library hBayesDM, a user-friendly package that offers hierarchical Bayesian analysis of various computational models on an array of decision-making tasks.\n\nIt uses STAN for Bayesian inference and supports both {R} and {Python}. hBayesDM‚Äôs goal is to help interpreting experimental data through computational models using a full Bayesian statistical inference approach with MCMC sampling. My work involved the implementation of the Q-learning algorithm for reinforcement learning tasks.\n\n Check out the project on GitHub."
  },
  {
    "objectID": "projects/CNN/index.html",
    "href": "projects/CNN/index.html",
    "title": "Look a doggo!: A deep learning approach to detect dogs in images",
    "section": "",
    "text": "Algorithm for a Dog Identification App\nThe goal of this project was to build a pipeline that can be used within a web or mobile app to process real-world, user-supplied images. Given an image of a dog, the algorithm will identify an estimate of the canine‚Äôs breed. If supplied an image of a human, the code will identify the resembling dog breed.\nI used python and keras interface from tensorflow to build a Convolutional Neural Networks (CNN) to classify dog breeds. The model was trained on the Dog Breed Identification dataset. The dataset contains 8351 dog images and 133 breeds.\n\nOpen it full\n\n Check out the project on GitHub."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "tl;dr\n\nPassionated about code  Bayesian stats  DevOps  Neurosciences  machine learning  beer  wine  coffee  travel  and striving for balance  I love abstract and conceptual thinking and am always trying to learn something new"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Projects\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nCycling Through Data: ProVelo‚Äôs Innovative Road Safety Dashboard\n\n\n\n\n\n\n\nR\n\n\nShiny\n\n\nData Visualization\n\n\nApp\n\n\nData Wrangling\n\n\n\n\n\n\n\n\n\n\n\nAug 13, 2024\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nBiodiversity Bonanza: Crafting a Shiny Species Spotter!\n\n\n\n\n\n\n\nR\n\n\nShiny\n\n\nData Visualization\n\n\nApp\n\n\nData Wrangling\n\n\n\n\n\n\n\n\n\n\n\nAug 9, 2024\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nLook a doggo!: A deep learning approach to detect dogs in images\n\n\n\n\n\n\n\nDeep Learning\n\n\nCNN\n\n\ntensorflow\n\n\nPython\n\n\nMachine Learning\n\n\nAlgorithm\n\n\nComputer Vision\n\n\nVGG16\n\n\nResnet_50\n\n\n\n\n\n\n\n\n\n\n\nMar 11, 2024\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nDbVieweR\n\n\n\n\n\n\n\nPackage\n\n\nR\n\n\nDBMS\n\n\nSQL\n\n\n\n\n\n\n\n\n\n\n\nFeb 12, 2024\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nWe Data Association\n\n\n\n\n\n\n\nVulgarisation\n\n\nData Science\n\n\nComputer Science\n\n\nStatistics\n\n\nTeaching\n\n\nYouTube\n\n\nBlog\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2023\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nShiny Usage Monitor\n\n\n\n\n\n\n\nShiny\n\n\nR\n\n\nApp\n\n\nMonitor\n\n\nStatistics\n\n\n\n\n\n\n\n\n\n\n\nJul 12, 2022\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nEcharts4r\n\n\n\n\n\n\n\nPackage\n\n\nR\n\n\nInteractive\n\n\nDataViz\n\n\n\n\n\n\n\n\n\n\n\nApr 12, 2022\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nDeep Reinforcement Learning with PyTorch (Super Mario Bros)\n\n\n\n\n\n\n\nDeep Learning\n\n\nAI\n\n\nPyTorch\n\n\nPython\n\n\nMachine Learning\n\n\nAlgorithm\n\n\nGames\n\n\n\n\n\n\n\n\n\n\n\nFeb 4, 2022\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nLeek Wars: Training AI agents to beat each other in a game\n\n\n\n\n\n\n\nAI\n\n\nReinforcement Learning\n\n\nAlgorithm\n\n\nGames\n\n\nJavaScript\n\n\n\n\n\n\n\n\n\n\n\nJul 8, 2021\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nHierarchical Bayesian Modeling\n\n\n\n\n\n\n\nBayesian Modeling\n\n\nStatistics\n\n\nPackage\n\n\nR\n\n\nSTAN\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nMar 8, 2021\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nCellular Automata: Conway‚Äôs Game of Life\n\n\n\n\n\n\n\nPython\n\n\nGames\n\n\nMachine Learning\n\n\nAI\n\n\nAlgorithm\n\n\n\n\n\n\n\n\n\n\n\nMay 6, 2019\n\n\nDavid Munoz Tord\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#fa-hand-peace-hi-im-david.-fa-hand-peace-im-a-data-scientist-r-developer-always-looking-for-a-cool-open-source-project",
    "href": "index.html#fa-hand-peace-hi-im-david.-fa-hand-peace-im-a-data-scientist-r-developer-always-looking-for-a-cool-open-source-project",
    "title": "David Munoz Tord",
    "section": " Hi, I‚Äôm David.   I‚Äôm a Data Scientist / R Developer always looking for a cool open-source project ! ",
    "text": "Hi, I‚Äôm David.   I‚Äôm a Data Scientist / R Developer always looking for a cool open-source project !"
  },
  {
    "objectID": "vitae.html",
    "href": "vitae.html",
    "title": "Full CV",
    "section": "",
    "text": "Download PDF\n\n\n\n\n\n I believe that the 21st century requires a more multifaceted toolkit if we hope to solve complex challenges‚Äìprocess and task oriented approaches balanced within a framework that fosters strategic thinking. That interdisciplinary relationships can be strengthened through active community participation‚Äìworking toward something with the shared value of doing good.\n I bring a lot of energy and enthusiasm to the projects that I become involved in. I thrive in situations that require imagination and innovation. My interests are varied; among my passions I would list: academic inquiry, classical and contemporary thought, the music and cuisine of other cultures, the arts, traveling, languages, and social justice. I believe that our most vulnerable deserve respect and to be treated with dignity and fairness.\n Ultimately I hope that the work I do is helpful‚Äìthat it enables discovery or provides clarity. I hope to bring together practical and principled approaches and I hope to further grow as this philosophy guides me.\n\n\n\n\n\n\n I am dedicated and hard working ‚Äî a good communicator and active community participant. I work well on team efforts and projects with the ultimate aim of using data for social good.\n\n\n\n I am:\n\n creative\n honest\n friendly\n enthusiastic\n keen to learn new things and take on new roles\n reliable\n a lateral thinker\n motivated\n\n\n\n\n I am able to:\n\n listen to and follow instructions accurately\n work cooperatively\n take on new challenges\n complete tasks\n support others\n identify new innovations and technologies while working toward implementing them\n be proactive\n speak and read in French, Spanish, and English\n read and understand some Japanese\n\n\n\n\n\n\n\n Coding: R, Python, STAN, BASH, SQL and JavaScript.\n Data: Relational Databases (data modeling and SQL); Extract-Transfer-Load (ETL) strategies for data engineering ‚Äî specifically with Apache NIFI for ETL; information retrieval; and, knowledge organizational theory. I have created my own DBMS in R and Shiny that uses PostgreSQL and SQLite as back-ends.\n Data Science: both R and Python are a big part of my workflow from reading in data, transforming and tidying data, exploring and visualizing data, modeling, reporting, presenting, and tying it all together in a dashboard. In connection to R, I am a proponent of the tidyverse framework for its unifying API. With respect to Python, I enjoy using polars, pyjanitor, pymc, and plotly to work in equivalent ways. However I honestly prefer working in R. I am of course familiar with the scikit-learn and tensorflow libraries in Python. I have experience with spark as well, plus torch and keras for R. I have also worked with brms and hBayesDM for Bayesian modeling.\n Web Technologies: HTML, CSS, Javascript; Quarto publishing; Rmarkdown Websites, Dashboards in R with shiny/flexdashboard that support crosstalk, and interactive data visualization with echarts; Static Site Generators, i.e., Hugo, and others.\n OSs: macOS, Linux, and containers. Within the Linux ecosystem, I have experience with Debian based distributions as well as Red Hat Enterprise Linux. I love the terminal and wish vim bindings were universal.\n DevOps tools: Fair knowledge of AWS and its services, including S3, Sagemaker, Glue, and EKS. I have also worked with Azure DevOps. I am very familiar with git and github and have experience with github actions for CI/CD. I have also worked with Docker and I have some MlOps experience.\n\n\n\n\n\n Doctor of Philosophy (Ph.D.) in Neurosciences - University of Geneva, Switerland / Mar 2019 ‚Äë Nov 2022\n\nResearch focus on computational models of addiction\nThesis Title: ‚ÄúLearning and Decision Making in Addiction: A Computational Approach‚Äù\nDiscontinued studies after 2.5 years\n\n Master in Neurosciences - University of Geneva, Switzerland / Sep 2018 ‚Äë Mar 2019 \n\nThesis: ‚ÄúDifferential contributions of ventral striatum subregions to the affective processing of reward‚Äù\nCollaborated with CalTech data engineers to implement tICA for better identification of activation and artifact components in fMRI.\n\n Complementary Studies in Data Science - Smith College, MA, USA / Sep 2017 ‚Äë Jun 2018\n\nCapstone project: Leveraged SQL and R to create a comprehensive analysis of the entertainment industry‚Äôs network using the IMDb database.\n\n Bachelor of Science in Psychology - University of Geneva, Switzerland /Sep 2014 ‚Äë Jun 2017\n\nRelevant coursework completed in statistics and scientific programming.\n\n\n\n\n\n\n Data Sctuctures and Algorithms\n Data Mining\n Machine Learning\n Artificial Intelligence\n Linux System Administration\n Visualization for Scientific Data\n Database Management Systems\n Object-Oriented Programming\n Spatial Analysis\n\n\n\n\n\n\n\n\n\n Led the development and launch of a scientific project in collaboration with EPFL, transitioning initial scripts into a comprehensive Software as a Service (SaaS) solution accessible to clients via Elastic Kubernetes Service (EKS) on AWS.\n\n\n Offered technical consulting services to a startup specializing in cognitive and educational technologies, translating academic research in cognitive neuroscience and developmental psychology into actionable solutions, while also advising on machine learning implementations.\n\n\n Collaborated closely with analysts across departments to design, build, and deploy various initiatives within the data platform, including the development, deployment, and maintenance of data services using R and PostgreSQL. Additionally, implemented best practices for continuous process automation, resulting in significant time savings for month-end processing.\n\n\n \n\n\n\n\n Conducted in-depth data analysis to classify customers using Bayesian inference, revealing distinct segments and patterns for data-driven decision-making and targeted strategies.\n\n\n Designed and implemented Apache NiFi ETL for efficient data processing and orchestration, contributing to streamlined data engineering workflows.\n\n\n Developed new internal tools for data analysts.\n\n\n \n\n\n\n\n Led the development of the data science infrastructure, creating an environment tailored for cutting-edge research and innovation.\n\n\n Developed and implemented complex statistical models in R to detect fraudulent transactions.\n\n\n Designed and maintained a data visualization dashboard in R Shiny, which allowed for easy monitoring of key performance indicators.\n\n\n \n\n\n\n\n Conducted lectures on statistics for the graduate program.\n\n\n Mentored and supervised graduate students in their statistical research projects, nurturing their analytical skills and research capabilities.\n\n\n Created and shared freely available data workshops in R and Python.\n\n\n\n\n\n\n\n Led an independent research project in Pr. Wraga‚Äôs visual cognition group.\n\n\n Designed and collected data for a cognitive neuroscience experiment.\n\n\n\n\n\n\n\n Led an independent research project as part of Dr.¬†Burra‚Äôs attentional capture group.\n\n\n Conducted signal processing of EEG data.\n\n\n\n\n\n\n\n echarts4r\n\nR, JavaScript - 2023 - Present\nCollaborated on the development of echarts4r, a R package that expands the capabilities of R-based interactive visualizations with a powerful rendering engine, while enhancing flexibility and ease of use.\n\n\n\n\n Firebase\n\nR, JavaScript - 2023 - Present\nContributed to the firebase integration package for R, empowering the Shiny user community by enabling user authentication and secure file storage through Firebase Storage.\n\n\n\n\n DbVieweR\n\nR, SQL - 2022 - Present\nCreated a shiny app simulating a database management system featuring functions like login authentication, save/create/delete tables, add/rename columns, using either a PostgreSQL or SQLite back-end. DbVieweR\n\n\n\n\n\n\n\n reprtree\n\nR - 2022\nIntegrated the caret ensemble for reprtree (implementation of representative trees from ensembles of tree-based machines).\n\n\n\n\n hBayesDM\n\nSTAN, R, Python - 2021\nCollaborated on the Hierarchical Bayesian modeling of Decision-Making tasks library. Built Q-learning algorithm for probabilistic selection task. hBayesDM\n\n\n\n\n 3dLMEr\n\nBASH, R - 2020\nCollaborated on the AFNI‚Äôs functions for 3Dimensional Linear Mixed-Effects Regression. Fixed residuals output image by adding bottom tolerance. 3dLMEr\n\n\n\n\n\n\n\n\n French (Mother Tongue)\n Spanish (Mother Tongue)\n English (Fluent)\n German (Basic)\n Italian (Basic)\n\n\n\n\n\n\n Top 2% on Stack Overflow in 2024\n Top 25% on GitHub in 2023\n Global Fellow scholarship recipient in 2017\n\n\n\n\n\n\n Contributing to We Data‚Äôs mission by facilitating workshops, providing statistics tutorials, and participating in coding demonstrations.\n Organizing R-Lunches at UniGe.\n Co-founder of Go-Fast, a socially responsible Bike Messenger cooperative in Geneva.\n Co-president of La Rustine, a non-profit organization promoting non-motorized mobility and self-sustainability in Switzerland.\n\n\n\n\n\n\n Artificial Intelligence\n Machine Learning\n Bayesian Statistics\n Natural Language Processing\n Data Visualization\n Ethics in Technology\n Data Privacy\n Data Engineering\n Cybersecurity\n Data Journalism\n\n  References Available upon request."
  },
  {
    "objectID": "vitae.html#fa-compass-personal-philosophy",
    "href": "vitae.html#fa-compass-personal-philosophy",
    "title": "Full CV",
    "section": "",
    "text": "I believe that the 21st century requires a more multifaceted toolkit if we hope to solve complex challenges‚Äìprocess and task oriented approaches balanced within a framework that fosters strategic thinking. That interdisciplinary relationships can be strengthened through active community participation‚Äìworking toward something with the shared value of doing good.\n I bring a lot of energy and enthusiasm to the projects that I become involved in. I thrive in situations that require imagination and innovation. My interests are varied; among my passions I would list: academic inquiry, classical and contemporary thought, the music and cuisine of other cultures, the arts, traveling, languages, and social justice. I believe that our most vulnerable deserve respect and to be treated with dignity and fairness.\n Ultimately I hope that the work I do is helpful‚Äìthat it enables discovery or provides clarity. I hope to bring together practical and principled approaches and I hope to further grow as this philosophy guides me."
  },
  {
    "objectID": "vitae.html#fa-magic-personal-skills",
    "href": "vitae.html#fa-magic-personal-skills",
    "title": "Full CV",
    "section": "",
    "text": "I am dedicated and hard working ‚Äî a good communicator and active community participant. I work well on team efforts and projects with the ultimate aim of using data for social good.\n\n\n\n I am:\n\n creative\n honest\n friendly\n enthusiastic\n keen to learn new things and take on new roles\n reliable\n a lateral thinker\n motivated\n\n\n\n\n I am able to:\n\n listen to and follow instructions accurately\n work cooperatively\n take on new challenges\n complete tasks\n support others\n identify new innovations and technologies while working toward implementing them\n be proactive\n speak and read in French, Spanish, and English\n read and understand some Japanese"
  },
  {
    "objectID": "vitae.html#fa-code-technical-skills",
    "href": "vitae.html#fa-code-technical-skills",
    "title": "Full CV",
    "section": "",
    "text": "Coding: R, Python, STAN, BASH, SQL and JavaScript.\n Data: Relational Databases (data modeling and SQL); Extract-Transfer-Load (ETL) strategies for data engineering ‚Äî specifically with Apache NIFI for ETL; information retrieval; and, knowledge organizational theory. I have created my own DBMS in R and Shiny that uses PostgreSQL and SQLite as back-ends.\n Data Science: both R and Python are a big part of my workflow from reading in data, transforming and tidying data, exploring and visualizing data, modeling, reporting, presenting, and tying it all together in a dashboard. In connection to R, I am a proponent of the tidyverse framework for its unifying API. With respect to Python, I enjoy using polars, pyjanitor, pymc, and plotly to work in equivalent ways. However I honestly prefer working in R. I am of course familiar with the scikit-learn and tensorflow libraries in Python. I have experience with spark as well, plus torch and keras for R. I have also worked with brms and hBayesDM for Bayesian modeling.\n Web Technologies: HTML, CSS, Javascript; Quarto publishing; Rmarkdown Websites, Dashboards in R with shiny/flexdashboard that support crosstalk, and interactive data visualization with echarts; Static Site Generators, i.e., Hugo, and others.\n OSs: macOS, Linux, and containers. Within the Linux ecosystem, I have experience with Debian based distributions as well as Red Hat Enterprise Linux. I love the terminal and wish vim bindings were universal.\n DevOps tools: Fair knowledge of AWS and its services, including S3, Sagemaker, Glue, and EKS. I have also worked with Azure DevOps. I am very familiar with git and github and have experience with github actions for CI/CD. I have also worked with Docker and I have some MlOps experience."
  },
  {
    "objectID": "vitae.html#fa-graduation-cap-education",
    "href": "vitae.html#fa-graduation-cap-education",
    "title": "Full CV",
    "section": "",
    "text": "Doctor of Philosophy (Ph.D.) in Neurosciences - University of Geneva, Switerland / Mar 2019 ‚Äë Nov 2022\n\nResearch focus on computational models of addiction\nThesis Title: ‚ÄúLearning and Decision Making in Addiction: A Computational Approach‚Äù\nDiscontinued studies after 2.5 years\n\n Master in Neurosciences - University of Geneva, Switzerland / Sep 2018 ‚Äë Mar 2019 \n\nThesis: ‚ÄúDifferential contributions of ventral striatum subregions to the affective processing of reward‚Äù\nCollaborated with CalTech data engineers to implement tICA for better identification of activation and artifact components in fMRI.\n\n Complementary Studies in Data Science - Smith College, MA, USA / Sep 2017 ‚Äë Jun 2018\n\nCapstone project: Leveraged SQL and R to create a comprehensive analysis of the entertainment industry‚Äôs network using the IMDb database.\n\n Bachelor of Science in Psychology - University of Geneva, Switzerland /Sep 2014 ‚Äë Jun 2017\n\nRelevant coursework completed in statistics and scientific programming."
  },
  {
    "objectID": "vitae.html#fa-chart-bar-coursework",
    "href": "vitae.html#fa-chart-bar-coursework",
    "title": "Full CV",
    "section": "",
    "text": "Data Sctuctures and Algorithms\n Data Mining\n Machine Learning\n Artificial Intelligence\n Linux System Administration\n Visualization for Scientific Data\n Database Management Systems\n Object-Oriented Programming\n Spatial Analysis"
  },
  {
    "objectID": "vitae.html#fa-institution-work-experience",
    "href": "vitae.html#fa-institution-work-experience",
    "title": "Full CV",
    "section": "",
    "text": "Led the development and launch of a scientific project in collaboration with EPFL, transitioning initial scripts into a comprehensive Software as a Service (SaaS) solution accessible to clients via Elastic Kubernetes Service (EKS) on AWS.\n\n\n Offered technical consulting services to a startup specializing in cognitive and educational technologies, translating academic research in cognitive neuroscience and developmental psychology into actionable solutions, while also advising on machine learning implementations.\n\n\n Collaborated closely with analysts across departments to design, build, and deploy various initiatives within the data platform, including the development, deployment, and maintenance of data services using R and PostgreSQL. Additionally, implemented best practices for continuous process automation, resulting in significant time savings for month-end processing.\n\n\n \n\n\n\n\n Conducted in-depth data analysis to classify customers using Bayesian inference, revealing distinct segments and patterns for data-driven decision-making and targeted strategies.\n\n\n Designed and implemented Apache NiFi ETL for efficient data processing and orchestration, contributing to streamlined data engineering workflows.\n\n\n Developed new internal tools for data analysts.\n\n\n \n\n\n\n\n Led the development of the data science infrastructure, creating an environment tailored for cutting-edge research and innovation.\n\n\n Developed and implemented complex statistical models in R to detect fraudulent transactions.\n\n\n Designed and maintained a data visualization dashboard in R Shiny, which allowed for easy monitoring of key performance indicators.\n\n\n \n\n\n\n\n Conducted lectures on statistics for the graduate program.\n\n\n Mentored and supervised graduate students in their statistical research projects, nurturing their analytical skills and research capabilities.\n\n\n Created and shared freely available data workshops in R and Python.\n\n\n\n\n\n\n\n Led an independent research project in Pr. Wraga‚Äôs visual cognition group.\n\n\n Designed and collected data for a cognitive neuroscience experiment.\n\n\n\n\n\n\n\n Led an independent research project as part of Dr.¬†Burra‚Äôs attentional capture group.\n\n\n Conducted signal processing of EEG data."
  },
  {
    "objectID": "vitae.html#fa-cube-open-source-contributions",
    "href": "vitae.html#fa-cube-open-source-contributions",
    "title": "Full CV",
    "section": "",
    "text": "echarts4r\n\nR, JavaScript - 2023 - Present\nCollaborated on the development of echarts4r, a R package that expands the capabilities of R-based interactive visualizations with a powerful rendering engine, while enhancing flexibility and ease of use.\n\n\n\n\n Firebase\n\nR, JavaScript - 2023 - Present\nContributed to the firebase integration package for R, empowering the Shiny user community by enabling user authentication and secure file storage through Firebase Storage.\n\n\n\n\n DbVieweR\n\nR, SQL - 2022 - Present\nCreated a shiny app simulating a database management system featuring functions like login authentication, save/create/delete tables, add/rename columns, using either a PostgreSQL or SQLite back-end. DbVieweR\n\n\n\n\n\n\n\n reprtree\n\nR - 2022\nIntegrated the caret ensemble for reprtree (implementation of representative trees from ensembles of tree-based machines).\n\n\n\n\n hBayesDM\n\nSTAN, R, Python - 2021\nCollaborated on the Hierarchical Bayesian modeling of Decision-Making tasks library. Built Q-learning algorithm for probabilistic selection task. hBayesDM\n\n\n\n\n 3dLMEr\n\nBASH, R - 2020\nCollaborated on the AFNI‚Äôs functions for 3Dimensional Linear Mixed-Effects Regression. Fixed residuals output image by adding bottom tolerance. 3dLMEr"
  },
  {
    "objectID": "vitae.html#fa-language-languages",
    "href": "vitae.html#fa-language-languages",
    "title": "Full CV",
    "section": "",
    "text": "French (Mother Tongue)\n Spanish (Mother Tongue)\n English (Fluent)\n German (Basic)\n Italian (Basic)"
  },
  {
    "objectID": "vitae.html#fa-trophy-accomplishments",
    "href": "vitae.html#fa-trophy-accomplishments",
    "title": "Full CV",
    "section": "",
    "text": "Top 2% on Stack Overflow in 2024\n Top 25% on GitHub in 2023\n Global Fellow scholarship recipient in 2017"
  },
  {
    "objectID": "vitae.html#fa-user-extracurricular-activities",
    "href": "vitae.html#fa-user-extracurricular-activities",
    "title": "Full CV",
    "section": "",
    "text": "Contributing to We Data‚Äôs mission by facilitating workshops, providing statistics tutorials, and participating in coding demonstrations.\n Organizing R-Lunches at UniGe.\n Co-founder of Go-Fast, a socially responsible Bike Messenger cooperative in Geneva.\n Co-president of La Rustine, a non-profit organization promoting non-motorized mobility and self-sustainability in Switzerland."
  },
  {
    "objectID": "vitae.html#fa-lightbulb-interests",
    "href": "vitae.html#fa-lightbulb-interests",
    "title": "Full CV",
    "section": "",
    "text": "Artificial Intelligence\n Machine Learning\n Bayesian Statistics\n Natural Language Processing\n Data Visualization\n Ethics in Technology\n Data Privacy\n Data Engineering\n Cybersecurity\n Data Journalism\n\n  References Available upon request."
  },
  {
    "objectID": "services/dataviz/index.html",
    "href": "services/dataviz/index.html",
    "title": "David Munoz Tord",
    "section": "",
    "text": "Creation of static and interactive dataviz, review of scientific figures.\n\nI‚Äôm an expert in the field of dataviz. I‚Äôve created several tutorials and given talks on this topic.\nI can help you to:\n\n Creation and review of graphs for scientific publication.\n Development of data application using R and Shiny.\n Creation of custom data visualization for the web.\n Dashboard creation for real time data analysis.\n Visualization of geospatial data.\n\n\n\n\n\n\n I maintain and develop echarts4r, a declarative framework for rapid construction of Web-based data visualization.\n I reviewed and improved scientific figures for research publications, ensuring clarity and accuracy in data representation.\n I conducted several workshops on data visualization techniques, covering topics such as chart types, color theory, and storytelling with data.\n\n\n\n\n\nIf you‚Äôre interested in learning more about how I can assist with your project, feel free to reach out at david.munoztord@mailbox.org."
  },
  {
    "objectID": "services/dataviz/index.html#fa-chart-bar-data-visualization",
    "href": "services/dataviz/index.html#fa-chart-bar-data-visualization",
    "title": "David Munoz Tord",
    "section": "",
    "text": "Creation of static and interactive dataviz, review of scientific figures.\n\nI‚Äôm an expert in the field of dataviz. I‚Äôve created several tutorials and given talks on this topic.\nI can help you to:\n\n Creation and review of graphs for scientific publication.\n Development of data application using R and Shiny.\n Creation of custom data visualization for the web.\n Dashboard creation for real time data analysis.\n Visualization of geospatial data.\n\n\n\n\n\n\n I maintain and develop echarts4r, a declarative framework for rapid construction of Web-based data visualization.\n I reviewed and improved scientific figures for research publications, ensuring clarity and accuracy in data representation.\n I conducted several workshops on data visualization techniques, covering topics such as chart types, color theory, and storytelling with data.\n\n\n\n\n\nIf you‚Äôre interested in learning more about how I can assist with your project, feel free to reach out at david.munoztord@mailbox.org."
  },
  {
    "objectID": "services/mining/index.html",
    "href": "services/mining/index.html",
    "title": "David Munoz Tord",
    "section": "",
    "text": "Data exploration, application of statistical methods, reproducible data analysis.\n Crunch the data to get answer to your question. Give insight to the information.\nI can help you to:\n\n Exploratory analysis of a dataset.\n Creation of clean and reproducible reports using Rmardown and Shiny.\n Application of statistical methods on your dataset.\n Creation of custom scripts for analyzing/ingesting your data automatically\n\n\n\n\n\n\n I‚Äôm the author of several scientific publications where I was in charge to explore and understand complex dataset in order to answer scientific questions.\n I built machine learning pipelines to implement predictive models to detect fraud in clients behavior and analyze it..\n - Designed and implemented Apache NiFi ETL for efficient data processing and orchestration, contributing to streamlined data workflows.\n\n\n\n\n\nIf you‚Äôre interested in learning more about how I can assist with your project, feel free to reach out at david.munoztord@mailbox.org."
  },
  {
    "objectID": "services/mining/index.html#fa-search-data-science-and-analysis",
    "href": "services/mining/index.html#fa-search-data-science-and-analysis",
    "title": "David Munoz Tord",
    "section": "",
    "text": "Data exploration, application of statistical methods, reproducible data analysis.\n Crunch the data to get answer to your question. Give insight to the information.\nI can help you to:\n\n Exploratory analysis of a dataset.\n Creation of clean and reproducible reports using Rmardown and Shiny.\n Application of statistical methods on your dataset.\n Creation of custom scripts for analyzing/ingesting your data automatically\n\n\n\n\n\n\n I‚Äôm the author of several scientific publications where I was in charge to explore and understand complex dataset in order to answer scientific questions.\n I built machine learning pipelines to implement predictive models to detect fraud in clients behavior and analyze it..\n - Designed and implemented Apache NiFi ETL for efficient data processing and orchestration, contributing to streamlined data workflows.\n\n\n\n\n\nIf you‚Äôre interested in learning more about how I can assist with your project, feel free to reach out at david.munoztord@mailbox.org."
  },
  {
    "objectID": "services/data_engineering/index.html",
    "href": "services/data_engineering/index.html",
    "title": "David Munoz Tord",
    "section": "",
    "text": "A data project always start with a data engineering step. You need to harvest data and store it in an adequate format to be able to use it. Let me help you with it !\nI can help you to:\n\n Harvest data from various sources, including APIs, SQL databases, or complex Excel spreadsheets.\n Reformat and reshape data to facilitate further analysis.\n Clean datasets to remove outliers and aberrant data points.\n Develop reproducible data preparation workflows.\n Automate the creation of data-related reports.\n\n\n\n\n\n\n Led development and launch of a collaborative project with EPFL, transitioning scripts into a Software as a Service (SaaS) solution on AWS.\n Provided technical consulting to a startup, translating academic research into actionable solutions and advising on machine learning.\n Collaborated across departments to design and deploy data platform initiatives, implementing automation for time savings.\n\n\n\n\n\nIf you‚Äôre interested in learning more about how I can assist with your project, feel free to reach out at david.munoztord@mailbox.org."
  },
  {
    "objectID": "services/data_engineering/index.html#fa-cog-data-engineering",
    "href": "services/data_engineering/index.html#fa-cog-data-engineering",
    "title": "David Munoz Tord",
    "section": "",
    "text": "A data project always start with a data engineering step. You need to harvest data and store it in an adequate format to be able to use it. Let me help you with it !\nI can help you to:\n\n Harvest data from various sources, including APIs, SQL databases, or complex Excel spreadsheets.\n Reformat and reshape data to facilitate further analysis.\n Clean datasets to remove outliers and aberrant data points.\n Develop reproducible data preparation workflows.\n Automate the creation of data-related reports.\n\n\n\n\n\n\n Led development and launch of a collaborative project with EPFL, transitioning scripts into a Software as a Service (SaaS) solution on AWS.\n Provided technical consulting to a startup, translating academic research into actionable solutions and advising on machine learning.\n Collaborated across departments to design and deploy data platform initiatives, implementing automation for time savings.\n\n\n\n\n\nIf you‚Äôre interested in learning more about how I can assist with your project, feel free to reach out at david.munoztord@mailbox.org."
  },
  {
    "objectID": "services/teaching/index.html",
    "href": "services/teaching/index.html",
    "title": "David Munoz Tord",
    "section": "",
    "text": "Short talks or multi-day courses on dataviz, R, ggplot2, data analytics and more.\n\nI have a passion for teaching and have conducted numerous workshops and training sessions on various topics related to data science and analytics.\nI can help you to:\n\n Conducting short talks or multi-day courses on data visualization, R programming, ggplot2, reproducible research, bayesian statistics, and data analytics.\n Providing customized training sessions tailored to your specific needs and objectives.\n\n\n\n\n\n\n I delivered a series of short talks on data visualization techniques for undergraduate students, covering fundamental principles and practical tips for creating effective visualizations.\n I taught a multi-day course on R programming for beginners, covering topics such as data manipulation, visualization, and basic statistical analysis.\n I organized and facilitated a workshop on ggplot2, a popular data visualization package in R, demonstrating how to create customized plots and advanced visualizations.\n I provided training sessions on data analytics tools and techniques to professionals in the industry, helping them develop skills in data exploration, modeling, and interpretation.\n Additionally, I have contributed to educational materials, such as this repository, where I share resources and tutorials for learning data science concepts and tools.\n I have also been a guest on several podcasts, discussing topics related to data science, analytics, and visualization.\n\n\n\n\n\nTell me more about your training needs at david.munoztord@mailbox.org to see if we can work together."
  },
  {
    "objectID": "services/teaching/index.html#fa-university-teaching-training",
    "href": "services/teaching/index.html#fa-university-teaching-training",
    "title": "David Munoz Tord",
    "section": "",
    "text": "Short talks or multi-day courses on dataviz, R, ggplot2, data analytics and more.\n\nI have a passion for teaching and have conducted numerous workshops and training sessions on various topics related to data science and analytics.\nI can help you to:\n\n Conducting short talks or multi-day courses on data visualization, R programming, ggplot2, reproducible research, bayesian statistics, and data analytics.\n Providing customized training sessions tailored to your specific needs and objectives.\n\n\n\n\n\n\n I delivered a series of short talks on data visualization techniques for undergraduate students, covering fundamental principles and practical tips for creating effective visualizations.\n I taught a multi-day course on R programming for beginners, covering topics such as data manipulation, visualization, and basic statistical analysis.\n I organized and facilitated a workshop on ggplot2, a popular data visualization package in R, demonstrating how to create customized plots and advanced visualizations.\n I provided training sessions on data analytics tools and techniques to professionals in the industry, helping them develop skills in data exploration, modeling, and interpretation.\n Additionally, I have contributed to educational materials, such as this repository, where I share resources and tutorials for learning data science concepts and tools.\n I have also been a guest on several podcasts, discussing topics related to data science, analytics, and visualization.\n\n\n\n\n\nTell me more about your training needs at david.munoztord@mailbox.org to see if we can work together."
  },
  {
    "objectID": "publications/sbm/index.html",
    "href": "publications/sbm/index.html",
    "title": "Sensory Brain Mapping",
    "section": "",
    "text": "Sensory Brain Mapping\nMy group from the Swiss Center of Affective Science investigated the neuronal networks underlying fundamental processes of taste perception.\nI processed all the MRI data of 97 individuals to analyze and summarize the results in support of the paper intitled 3D-Printed Mouthpiece for fMRI-Compatible Gustometers.\n\nMy work allowed to visualize the parameter distribution of the BOLD signal in 3D.\n\n\nCheck out the project on GitHub or the paper published in eNeuro."
  },
  {
    "objectID": "publications/vBMS/index.html",
    "href": "publications/vBMS/index.html",
    "title": "Voxel-wise Bayesian model selection",
    "section": "",
    "text": "Voxels-wise Bayesian model selection\nIs a technique to compare brain maps using Bayesian methods.\nBuilding and comparing brain maps between several models is a common task for neuroscientist.\n\nHere we performed a Bayesian model selection (BMS) to select the best model given the data for group-level analysis. This procedure computes the probability of the data given the model (model evidence) for a set of candidate models. It also allows to compare characterize maps‚Äùheat zones‚Äù and to visualize them.\n\n\nCheck out the project on GitHub or the paper published in the Journal of Neuroscience."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Contact\n\n\nContact me at david.munoztord@mailbox.org."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Blog\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nR and Python side-by-side for data wrangling\n\n\n\n\n\n\n\nPython\n\n\nR\n\n\nData Wrangling\n\n\nData Science\n\n\nPolars\n\n\n\n\n\n\n\n\n\n\n\nMar 27, 2024\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nR Lunches in university of Geneva\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nMay 13, 2023\n\n\n\n\n\n\n  \n\n\n\n\nWe-Data Live on YouTube\n\n\n\n\n\n\n\nYouTube\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nData Manipulation with R\n\n\n\n\n\n\n\nR\n\n\nInteractive Exercises\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\n\n\n\n\n  \n\n\n\n\nData Exploration with R\n\n\n\n\n\n\n\nR\n\n\nInteractive Exercises\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2022\n\n\n\n\n\n\n  \n\n\n\n\nData Viz Fundamentals with R\n\n\n\n\n\n\n\nR\n\n\nInteractive Exercises\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2022\n\n\n\n\n\n\nNo matching items"
  }
]