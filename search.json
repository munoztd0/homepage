[
  {
    "objectID": "publications/vBMS/index.html",
    "href": "publications/vBMS/index.html",
    "title": "Voxel-wise Bayesian model selection",
    "section": "",
    "text": "Voxels-wise Bayesian model selection\nIs a technique to compare brain maps using Bayesian methods.\nBuilding and comparing brain maps between several models is a common task for neuroscientist.\n\nHere we performed a Bayesian model selection (BMS) to select the best model given the data for group-level analysis. This procedure computes the probability of the data given the model (model evidence) for a set of candidate models. It also allows to compare characterize maps”heat zones” and to visualize them.\n\n\nCheck out the project on GitHub or the paper published in the Journal of Neuroscience."
  },
  {
    "objectID": "publications/sbm/index.html",
    "href": "publications/sbm/index.html",
    "title": "Sensory Brain Mapping",
    "section": "",
    "text": "Sensory Brain Mapping\nMy group from the Swiss Center of Affective Science investigated the neuronal networks underlying fundamental processes of taste perception.\nI processed all the MRI data of 97 individuals to analyze and summarize the results in support of the paper intitled 3D-Printed Mouthpiece for fMRI-Compatible Gustometers.\n\nMy work allowed to visualize the parameter distribution of the BOLD signal in 3D.\n\n\nCheck out the project on GitHub or the paper published in eNeuro."
  },
  {
    "objectID": "projects/CNN/index.html",
    "href": "projects/CNN/index.html",
    "title": "Look a doggo!: A deep learning approach to detect dogs in images",
    "section": "",
    "text": "Algorithm for a Dog Identification App\nThe goal of this project was to build a pipeline that can be used within a web or mobile app to process real-world, user-supplied images. Given an image of a dog, the algorithm will identify an estimate of the canine’s breed. If supplied an image of a human, the code will identify the resembling dog breed.\nI used python and keras interface from tensorflow to build a Convolutional Neural Networks (CNN) to classify dog breeds. The model was trained on the Dog Breed Identification dataset. The dataset contains 8351 dog images and 133 breeds.\n\n Check out the project on GitHub."
  },
  {
    "objectID": "projects/DbVieweR/index.html",
    "href": "projects/DbVieweR/index.html",
    "title": "DbVieweR",
    "section": "",
    "text": "DbVieweR an R package for database management\nDbVieweR is a Shiny app that simulates a database management system, featuring functions like login/logout, save/create/delete tables, and add/rename columns.\n\n\n\n\n Demo \n\n\nDescription\n\n\n\nHighlights of this app:  - Back-end database: Utilizes SQLite or PostgreSQL for storing dummy data. - Authorization: Incorporates the shinyauthr package to add an authentication layer to the app.  Features of the app:  - Save tables: Store sales summary tables in the database. - Update existing tables: Rename tables or columns. - Create new tables: Customize table and column names, with options for integer, float, varchar(255), and boolean columns. - Create entries: Add entries to tables with customizable column types. - Delete tables: Accessible only with specific authorization. - Robustness: Defense mechanism prevents duplicates, invalid expressions, and conflicts with SQL keywords.  Check out the project on GitHub."
  },
  {
    "objectID": "projects/WeData/index.html",
    "href": "projects/WeData/index.html",
    "title": "We Data Association",
    "section": "",
    "text": "We Data Association\nWe are an association of the University of Geneva that aims to share its passion for data science and computer science. We have a strong interest in statistics and computational methods. Initially, the association’s target audience was people in the social sciences but we quickly expanded into other fields of research.\nMore concretely, the association aims to achieve its objectives by creating freely-accessible educational content on its platforms in a variety of forms: YouTube videos, blog posts, exercises, etc. The association co-organizes the R-Lunches, a series of events related to R in which various speakers present topics related to the R language. The association tries to keep abreast of and participate as often as possible in digital initiatives at the University of Geneva.\n\n Check out the project on our website."
  },
  {
    "objectID": "projects/LeekWars/index.html",
    "href": "projects/LeekWars/index.html",
    "title": "Leek Wars: Training AI agents to beat each other in a game",
    "section": "",
    "text": "Leek Wars: Training AI agents to compete in a game\nLeek Wars is a multiplayer Artifical Intelligence programming game. The language of Leek Wars is LeekScript. Follow my best leek @leakit22 ! I remain in the top 300 for the time being.\n\n Check out the project on GitHub."
  },
  {
    "objectID": "projects/hBDM/index.html",
    "href": "projects/hBDM/index.html",
    "title": "Hierarchical Bayesian Modeling",
    "section": "",
    "text": "Hierarchical Bayesian modeling of Decision-Making tasks\nI collaborated on the Hierarchical Bayesian modeling of Decision-Making tasks library hBayesDM, a user-friendly package that offers hierarchical Bayesian analysis of various computational models on an array of decision-making tasks.\n\nIt uses STAN for Bayesian inference and supports both {R} and {Python}. hBayesDM’s goal is to help interpreting experimental data through computational models using a full Bayesian statistical inference approach with MCMC sampling. My work involved the implementation of the Q-learning algorithm for reinforcement learning tasks.\n\n Check out the project on GitHub."
  },
  {
    "objectID": "projects/GameOfLife/index.html",
    "href": "projects/GameOfLife/index.html",
    "title": "Cellular Automata: Conway’s Game of Life",
    "section": "",
    "text": "Conway’s Game Of Life implemented in Python\nConway’s Game of Life is a cellular automaton devised by the British mathematician John Horton Conway in 1970. The game is a zero-player game, meaning that its evolution is determined by its initial state, requiring no further input. One interacts with the Game of Life by creating an initial configuration and observing how it evolves.\nA given cell (i, j) in the simulation is accessed on a grid [i][j], where i and j are the row and column indices, respectively. The value of a given cell at a given instant of time depends on the state of its neighbors at the previous time step.\nConway’s Game of Life has four rules:\n\nIf a cell is ON and has fewer than two neighbors that are ON, it turns OFF.\nIf a cell is ON and has either two or three neighbors that are ON, it remains ON.\nIf a cell is ON and has more than three neighbors that are ON, it turns OFF.\nIf a cell is OFF and has exactly three neighbors that are ON, it turns ON.\n\nThe bulk of the graphical implementation was made using PyGame.\n\nCheck out the project on GitHub."
  },
  {
    "objectID": "projects/MonitoR/index.html",
    "href": "projects/MonitoR/index.html",
    "title": "Shiny Usage Monitor",
    "section": "",
    "text": "Know thyself\nKeeping track of the number of users on your Shiny Server is helpful for several reasons:\n\n Identifies low-traffic periods (best times to push updates or restart the server).\n Tells you if you need to pay more attention to scaling your apps (i.e. adjust server size, optimize slow apps).\n Shows which apps are most popular.\n Basic architecture.\n Deploy Shiny Server Open Source with one or more apps.\n Continuously check your server’s logs and save off data on the number of users on each app (check_server.R plus a cronjob).\n Use Shiny to display the data over time.\n\n\n\nCheck out the project on GitHub."
  },
  {
    "objectID": "projects/2022-12-echarts4r/index.html",
    "href": "projects/2022-12-echarts4r/index.html",
    "title": "Echarts4r",
    "section": "",
    "text": "Easy and beautiful interactive dataviz with Echarts4r!\nThis R package is a wrapper of the ECharts library. It provides a set of functions to generate interactive charts in R.\n\nlibrary(dplyr)\nlibrary(echarts4r)\nlibrary(lubridate)\n\n# Plot 1\nmtcars |&gt;\n  e_charts(cyl) |&gt; \n  e_boxplot(disp, colorBy=\"data\",) |&gt;\n  e_boxplot(hp, colorBy=\"data\",) |&gt;\n  e_boxplot(mpg, colorBy=\"data\",) |&gt;\n  e_tooltip(trigger = \"axis\") |&gt;\n  e_title(\"Descriptive Stats on mtcars Data\") |&gt;\n  e_toolbox_feature(feature = \"saveAsImage\")  # add the download button!\n\n\n\n\n# Plot 2\nlakers |&gt;           \n  mutate(date = lubridate::ymd(date)) |&gt;\n  mutate(points = points+runif(n=34624, min=-0.5, max=0.5) ) |&gt;\n  group_by(date) |&gt;\n  summarise(points2 = sum(points),\n            min= points2 - (50 +min(points)),\n            max=points2 + (50+max(points)) ) |&gt; \n  e_charts(date) |&gt;\n  e_line(points2) |&gt;\n  e_band2(min, max, color = \"lemonchiffon\") |&gt;\n  e_tooltip(trigger = \"axis\") |&gt;\n  e_title(\"Lakers Timeseries Data\") |&gt;\n  e_toolbox_feature(feature = \"saveAsImage\")  # add the download button!\n\n\n\n\n# Plot 3\nstarwars |&gt;\n  e_charts(mass) |&gt;\n  e_scatter(height, bind = name, symbol_size = 5, legend =F) |&gt;\n  e_datazoom() |&gt;\n  e_tooltip(\n    formatter = htmlwidgets::JS(\"\n      function(params){\n        return('&lt;strong&gt;' + params.name + \n                '&lt;/strong&gt;&lt;br /&gt;mass: ' + params.value[0] + \n                '&lt;br /&gt;height: ' + params.value[1]) \n                }\n    \")) |&gt; # little JS formatter to make it pretty\n  e_title(\"Starwars Outlier Data\") |&gt;\n  e_toolbox_feature(feature = \"saveAsImage\")  # add the download button!\n\n\n\n\n\n \n\n\n\n\n Full Screen\n\n\n\n\nDescription\n\n\n\nHighlights of this package:  - Provide functions to generate interactive charts in R. - The package is built on top of the ECharts library, which is a powerful library for data visualization. - The package provides a set of functions that can be used to generate charts with ECharts. - The package is still under development. More features will be added in the future. - The package is open source.\n Features of the package: \n\nProvides more than 20 chart types available out of the box, along with a dozen components, and each of them can be arbitrarily combined to use.\nHas a powerful rendering engine that allows you to easily switch between Canvas and SVG rendering. Progressive rendering and stream loading make it possible to render 10 million data in realtime.\nOffers professional data analysis through datasets, which support data transforms like filtering, clustering, and regression to help analyze multi-dimensional analysis of the same data.\nHas an elegant visual design that follows visualization principles and supports responsive design. Flexible configurations make it easy to customize.\nHas a healthy community that ensures the healthy development of the project and contributes a wealth of third-party extensions.\nIs accessibility-friendly with automatically generated chart descriptions and decal patterns that help users with disabilities understand the content and the stories behind the charts.\n\n\nYou can check the project on Github."
  },
  {
    "objectID": "projects/DeepLearning/index.html",
    "href": "projects/DeepLearning/index.html",
    "title": "Deep Reinforcement Learning with PyTorch (Super Mario Bros)",
    "section": "",
    "text": "Reinforcement Learning with PyTorch (Super Mario Bros)\nHere is a project I worked on to train AI agents to play and solve games using reinforcement learning. The project is based on the Super Mario Bros game, and the AI agents are trained using the Proximal Policy Optimization (PPO) algorithm. The agents are implemented using the PyTorch library, and the game environment is provided by the OpenAI Gym library . The project also includes a custom implementation of the game environment, which is based on the Super Mario Bros game for the Nintendo Entertainment System (NES). The game environment is implemented using the FCEUX emulator, and the game is controlled using the Python library PyAutoGUI.\n\nI also used TensorBoard to visualize and evaluate the quality metrics of the model.\n\n Check out the project on GitHub."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Projects\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nLook a doggo!: A deep learning approach to detect dogs in images\n\n\n\n\n\n\n\nDeep Learning\n\n\nCNN\n\n\ntensorflow\n\n\nPython\n\n\nMachine Learning\n\n\nAlgorithm\n\n\nComputer Vision\n\n\n\n\n\n\n\n\n\n\n\nMar 11, 2024\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nDbVieweR\n\n\n\n\n\n\n\nPackage\n\n\nR\n\n\nDBMS\n\n\nSQL\n\n\n\n\n\n\n\n\n\n\n\nFeb 12, 2024\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nWe Data Association\n\n\n\n\n\n\n\nVulgarisation\n\n\nData Science\n\n\nComputer Science\n\n\nStatistics\n\n\nTeaching\n\n\nYouTube\n\n\nBlog\n\n\n\n\n\n\n\n\n\n\n\nOct 10, 2023\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nShiny Usage Monitor\n\n\n\n\n\n\n\nShiny\n\n\nR\n\n\nApp\n\n\nMonitor\n\n\nStatistics\n\n\n\n\n\n\n\n\n\n\n\nJul 12, 2022\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nEcharts4r\n\n\n\n\n\n\n\nPackage\n\n\nR\n\n\nInteractive\n\n\nDataViz\n\n\n\n\n\n\n\n\n\n\n\nApr 12, 2022\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nDeep Reinforcement Learning with PyTorch (Super Mario Bros)\n\n\n\n\n\n\n\nDeep Learning\n\n\nAI\n\n\nPyTorch\n\n\nPython\n\n\nMachine Learning\n\n\nAlgorithm\n\n\nGames\n\n\n\n\n\n\n\n\n\n\n\nFeb 4, 2022\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nLeek Wars: Training AI agents to beat each other in a game\n\n\n\n\n\n\n\nAI\n\n\nReinforcement Learning\n\n\nAlgorithm\n\n\nGames\n\n\nJavaScript\n\n\n\n\n\n\n\n\n\n\n\nJul 8, 2021\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nHierarchical Bayesian Modeling\n\n\n\n\n\n\n\nBayesian Modeling\n\n\nStatistics\n\n\nPackage\n\n\nR\n\n\nSTAN\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nMar 8, 2021\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nCellular Automata: Conway’s Game of Life\n\n\n\n\n\n\n\nPython\n\n\nGames\n\n\nMachine Learning\n\n\nAI\n\n\nAlgorithm\n\n\n\n\n\n\n\n\n\n\n\nMay 6, 2019\n\n\nDavid Munoz Tord\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Talks, Podcasts & Worshops",
    "section": "",
    "text": "Talks, Podcasts & Worshops\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nDeploy Your R Code!\n\n\n\n\n\n\n\nTalk\n\n\nThoughts\n\n\nWeb\n\n\nR\n\n\nImplementing an idea\n\n\nDevOps\n\n\n\n\n\n\n\n\n\n\n\nApr 4, 2023\n\n\nDavid Munoz Tord\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/2023-04-Deploy-your-R-code/index.html",
    "href": "talks/2023-04-Deploy-your-R-code/index.html",
    "title": "Deploy Your R Code!",
    "section": "",
    "text": "Deploy Your R Code!\n\n\n\n\n\nFull Slides\nPresentation Recording"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Blog\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nYour first chat bot with python!\n\n\n\n\n\n\n\nPython\n\n\nAI\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2023\n\n\nDavid Munoz Tord\n\n\n\n\n\n\n  \n\n\n\n\nR Lunches in university of Geneva\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nMay 13, 2023\n\n\n\n\n\n\n  \n\n\n\n\nWe-Data Live on YouTube\n\n\n\n\n\n\n\nYouTube\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nData Manipulation with R\n\n\n\n\n\n\n\nR\n\n\nInteractive Exercises\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\n\n\n\n\n  \n\n\n\n\nData Exploration with R\n\n\n\n\n\n\n\nR\n\n\nInteractive Exercises\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2022\n\n\n\n\n\n\n  \n\n\n\n\nData Viz Fundamentals with R\n\n\n\n\n\n\n\nR\n\n\nInteractive Exercises\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Contact\n\n\nContact me at david.munoztord@mailbox.org."
  },
  {
    "objectID": "vitae.html",
    "href": "vitae.html",
    "title": "Full CV",
    "section": "",
    "text": "I believe that the 21st century requires a more multifaceted toolkit if we hope to solve complex challenges–process and task oriented approaches balanced within a framework that fosters strategic thinking. That interdisciplinary relationships can be strengthened through active community participation–working toward something with the shared value of doing good.\n I bring a lot of energy and enthusiasm to the projects that I become involved in. I thrive in situations that require imagination and innovation. My interests are varied; among my passions I would list: academic inquiry, classical and contemporary thought, the music and cuisine of other cultures, the arts, traveling, languages, and social justice. I believe that our most vulnerable deserve respect and to be treated with dignity and fairness.\n Ultimately I hope that the work I do is helpful–that it enables discovery or provides clarity. I hope to bring together practical and principled approaches and I hope to further grow as this philosophy guides me.\n\n\n\n\n\n\n I am dedicated and hard working — a good communicator and active community participant. I work well on team efforts and projects with the ultimate aim of using data for social good.\n\n\n\n I am:\n\n creative\n honest\n friendly\n enthusiastic\n keen to learn new things and take on new roles\n reliable\n a lateral thinker\n motivated\n\n\n\n\n I am able to:\n\n listen to and follow instructions accurately\n work cooperatively\n take on new challenges\n complete tasks\n support others\n identify new innovations and technologies while working toward implementing them\n be proactive\n speak and read in French, Spanish, and English\n read and understand some Japanese\n\n\n\n\n\n\n\n Coding: R, Python, STAN, BASH, SQL and JavaScript.\n Data: Relational Databases (data modeling and SQL); Extract-Transfer-Load (ETL) strategies for data engineering — specifically with Apache NIFI for ETL; information retrieval; and, knowledge organizational theory. I have created my own DBMS in R and Shiny that uses PostgreSQL and SQLite as back-ends.\n Data Science: both R and Python are a big part of my workflow from reading in data, transforming and tidying data, exploring and visualizing data, modeling, reporting, presenting, and tying it all together in a dashboard. In connection to R, I am a proponent of the tidyverse framework for its unifying API. With respect to Python, I enjoy using polars, pyjanitor, pymc, and plotly to work in equivalent ways. However I honestly prefer working in R. I am of course familiar with the scikit-learn and tensorflow libraries in Python. I have experience with spark as well, plus torch and keras for R. I have also worked with brms and hBayesDM for Bayesian modeling.\n Web Technologies: HTML, CSS, Javascript; Quarto publishing; Rmarkdown Websites, Dashboards in R with shiny/flexdashboard that support crosstalk, and interactive data visualization with echarts; Static Site Generators, i.e., Hugo, and others.\n OSs: macOS, Linux, and containers. Within the Linux ecosystem, I have experience with Debian based distributions as well as Red Hat Enterprise Linux. I love the terminal and wish vim bindings were universal.\n DevOps tools: Fair knowledge of AWS and its services, including S3, Sagemaker, Glue, and EKS. I have also worked with Azure DevOps. I am very familiar with git and github and have experience with github actions for CI/CD. I have also worked with Docker and I have some MlOps experience.\n\n\n\n\n\n Doctor of Philosophy (Ph.D.) in Neurosciences - University of Geneva, Switerland / Mar 2019 ‑ Nov 2022\n\nResearch focus on computational models of addiction\nThesis Title: “Learning and Decision Making in Addiction: A Computational Approach”\nDiscontinued studies after 2.5 years\n\n Master in Neurosciences - University of Geneva, Switzerland / Sep 2018 ‑ Mar 2019 \n\nThesis: “Differential contributions of ventral striatum subregions to the affective processing of reward”\nCollaborated with CalTech data engineers to implement tICA for better identification of activation and artifact components in fMRI.\n\n Complementary Studies in Data Science - Smith College, MA, USA / Sep 2017 ‑ Jun 2018\n\nCapstone project: Leveraged SQL and R to create a comprehensive analysis of the entertainment industry’s network using the IMDb database.\n\n Bachelor of Science in Psychology - University of Geneva, Switzerland /Sep 2014 ‑ Jun 2017\n\nRelevant coursework completed in statistics and scientific programming.\n\n\n\n\n\n\n Data Sctuctures and Algorithms\n Data Mining\n Machine Learning\n Artificial Intelligence\n Linux System Administration\n Visualization for Scientific Data\n Database Management Systems\n Object-Oriented Programming\n Spatial Analysis\n\n\n\n\n\n\n\n\n\n Led the development and launch of a scientific project in collaboration with EPFL, transitioning initial scripts into a comprehensive Software as a Service (SaaS) solution accessible to clients via Elastic Kubernetes Service (EKS) on AWS.\n\n\n Offered technical consulting services to a startup specializing in cognitive and educational technologies, translating academic research in cognitive neuroscience and developmental psychology into actionable solutions, while also advising on machine learning implementations.\n\n\n Collaborated closely with analysts across departments to design, build, and deploy various initiatives within the data platform, including the development, deployment, and maintenance of data services using R and PostgreSQL. Additionally, implemented best practices for continuous process automation, resulting in significant time savings for month-end processing.\n\n\n \n\n\n\n\n Conducted in-depth data analysis to classify customers using Bayesian inference, revealing distinct segments and patterns for data-driven decision-making and targeted strategies.\n\n\n Designed and implemented Apache NiFi ETL for efficient data processing and orchestration, contributing to streamlined data engineering workflows.\n\n\n Developed new internal tools for data analysts.\n\n\n \n\n\n\n\n Led the development of the data science infrastructure, creating an environment tailored for cutting-edge research and innovation.\n\n\n Developed and implemented complex statistical models in R to detect fraudulent transactions.\n\n\n Designed and maintained a data visualization dashboard in R Shiny, which allowed for easy monitoring of key performance indicators.\n\n\n \n\n\n\n\n Conducted lectures on statistics for the graduate program.\n\n\n Mentored and supervised graduate students in their statistical research projects, nurturing their analytical skills and research capabilities.\n\n\n Created and shared freely available data workshops in R and Python.\n\n\n\n\n\n\n\n Led an independent research project in Pr. Wraga’s visual cognition group.\n\n\n Designed and collected data for a cognitive neuroscience experiment.\n\n\n\n\n\n\n\n Led an independent research project as part of Dr. Burra’s attentional capture group.\n\n\n Conducted signal processing of EEG data.\n\n\n\n\n\n\n\n echarts4r\n\nR, JavaScript - 2023 - Present\nCollaborated on the development of echarts4r, a R package that expands the capabilities of R-based interactive visualizations with a powerful rendering engine, while enhancing flexibility and ease of use.\n\n\n\n\n Firebase\n\nR, JavaScript - 2023 - Present\nContributed to the firebase integration package for R, empowering the Shiny user community by enabling user authentication and secure file storage through Firebase Storage.\n\n\n\n\n DbVieweR\n\nR, SQL - 2022 - Present\nCreated a shiny app simulating a database management system featuring functions like login authentication, save/create/delete tables, add/rename columns, using either a PostgreSQL or SQLite back-end. DbVieweR\n\n\n\n\n\n\n\n reprtree\n\nR - 2022\nIntegrated the caret ensemble for reprtree (implementation of representative trees from ensembles of tree-based machines).\n\n\n\n\n hBayesDM\n\nSTAN, R, Python - 2021\nCollaborated on the Hierarchical Bayesian modeling of Decision-Making tasks library. Built Q-learning algorithm for probabilistic selection task. hBayesDM\n\n\n\n\n 3dLMEr\n\nBASH, R - 2020\nCollaborated on the AFNI’s functions for 3Dimensional Linear Mixed-Effects Regression. Fixed residuals output image by adding bottom tolerance. 3dLMEr\n\n\n\n\n\n\n\n\n French (Mother Tongue)\n Spanish (Mother Tongue)\n English (Fluent)\n German (Basic)\n Italian (Basic)\n\n\n\n\n\n\n Top 2% on Stack Overflow in 2024\n Top 25% on GitHub in 2023\n Global Fellow scholarship recipient in 2017\n\n\n\n\n\n\n Contributing to We Data’s mission by facilitating workshops, providing statistics tutorials, and participating in coding demonstrations.\n Organizing R-Lunches at UniGe.\n Co-founder of Go-Fast, a socially responsible Bike Messenger cooperative in Geneva.\n Co-president of La Rustine, a non-profit organization promoting non-motorized mobility and self-sustainability in Switzerland.\n\n\n\n\n\n\n Artificial Intelligence\n Machine Learning\n Bayesian Statistics\n Natural Language Processing\n Data Visualization\n Ethics in Technology\n Data Privacy\n Data Engineering\n Cybersecurity\n Data Journalism\n\n  References Available upon request."
  },
  {
    "objectID": "vitae.html#fa-compass-personal-philosophy",
    "href": "vitae.html#fa-compass-personal-philosophy",
    "title": "Full CV",
    "section": "",
    "text": "I believe that the 21st century requires a more multifaceted toolkit if we hope to solve complex challenges–process and task oriented approaches balanced within a framework that fosters strategic thinking. That interdisciplinary relationships can be strengthened through active community participation–working toward something with the shared value of doing good.\n I bring a lot of energy and enthusiasm to the projects that I become involved in. I thrive in situations that require imagination and innovation. My interests are varied; among my passions I would list: academic inquiry, classical and contemporary thought, the music and cuisine of other cultures, the arts, traveling, languages, and social justice. I believe that our most vulnerable deserve respect and to be treated with dignity and fairness.\n Ultimately I hope that the work I do is helpful–that it enables discovery or provides clarity. I hope to bring together practical and principled approaches and I hope to further grow as this philosophy guides me."
  },
  {
    "objectID": "vitae.html#fa-magic-personal-skills",
    "href": "vitae.html#fa-magic-personal-skills",
    "title": "Full CV",
    "section": "",
    "text": "I am dedicated and hard working — a good communicator and active community participant. I work well on team efforts and projects with the ultimate aim of using data for social good.\n\n\n\n I am:\n\n creative\n honest\n friendly\n enthusiastic\n keen to learn new things and take on new roles\n reliable\n a lateral thinker\n motivated\n\n\n\n\n I am able to:\n\n listen to and follow instructions accurately\n work cooperatively\n take on new challenges\n complete tasks\n support others\n identify new innovations and technologies while working toward implementing them\n be proactive\n speak and read in French, Spanish, and English\n read and understand some Japanese"
  },
  {
    "objectID": "vitae.html#fa-code-technical-skills",
    "href": "vitae.html#fa-code-technical-skills",
    "title": "Full CV",
    "section": "",
    "text": "Coding: R, Python, STAN, BASH, SQL and JavaScript.\n Data: Relational Databases (data modeling and SQL); Extract-Transfer-Load (ETL) strategies for data engineering — specifically with Apache NIFI for ETL; information retrieval; and, knowledge organizational theory. I have created my own DBMS in R and Shiny that uses PostgreSQL and SQLite as back-ends.\n Data Science: both R and Python are a big part of my workflow from reading in data, transforming and tidying data, exploring and visualizing data, modeling, reporting, presenting, and tying it all together in a dashboard. In connection to R, I am a proponent of the tidyverse framework for its unifying API. With respect to Python, I enjoy using polars, pyjanitor, pymc, and plotly to work in equivalent ways. However I honestly prefer working in R. I am of course familiar with the scikit-learn and tensorflow libraries in Python. I have experience with spark as well, plus torch and keras for R. I have also worked with brms and hBayesDM for Bayesian modeling.\n Web Technologies: HTML, CSS, Javascript; Quarto publishing; Rmarkdown Websites, Dashboards in R with shiny/flexdashboard that support crosstalk, and interactive data visualization with echarts; Static Site Generators, i.e., Hugo, and others.\n OSs: macOS, Linux, and containers. Within the Linux ecosystem, I have experience with Debian based distributions as well as Red Hat Enterprise Linux. I love the terminal and wish vim bindings were universal.\n DevOps tools: Fair knowledge of AWS and its services, including S3, Sagemaker, Glue, and EKS. I have also worked with Azure DevOps. I am very familiar with git and github and have experience with github actions for CI/CD. I have also worked with Docker and I have some MlOps experience."
  },
  {
    "objectID": "vitae.html#fa-graduation-cap-education",
    "href": "vitae.html#fa-graduation-cap-education",
    "title": "Full CV",
    "section": "",
    "text": "Doctor of Philosophy (Ph.D.) in Neurosciences - University of Geneva, Switerland / Mar 2019 ‑ Nov 2022\n\nResearch focus on computational models of addiction\nThesis Title: “Learning and Decision Making in Addiction: A Computational Approach”\nDiscontinued studies after 2.5 years\n\n Master in Neurosciences - University of Geneva, Switzerland / Sep 2018 ‑ Mar 2019 \n\nThesis: “Differential contributions of ventral striatum subregions to the affective processing of reward”\nCollaborated with CalTech data engineers to implement tICA for better identification of activation and artifact components in fMRI.\n\n Complementary Studies in Data Science - Smith College, MA, USA / Sep 2017 ‑ Jun 2018\n\nCapstone project: Leveraged SQL and R to create a comprehensive analysis of the entertainment industry’s network using the IMDb database.\n\n Bachelor of Science in Psychology - University of Geneva, Switzerland /Sep 2014 ‑ Jun 2017\n\nRelevant coursework completed in statistics and scientific programming."
  },
  {
    "objectID": "vitae.html#fa-chart-bar-coursework",
    "href": "vitae.html#fa-chart-bar-coursework",
    "title": "Full CV",
    "section": "",
    "text": "Data Sctuctures and Algorithms\n Data Mining\n Machine Learning\n Artificial Intelligence\n Linux System Administration\n Visualization for Scientific Data\n Database Management Systems\n Object-Oriented Programming\n Spatial Analysis"
  },
  {
    "objectID": "vitae.html#fa-institution-work-experience",
    "href": "vitae.html#fa-institution-work-experience",
    "title": "Full CV",
    "section": "",
    "text": "Led the development and launch of a scientific project in collaboration with EPFL, transitioning initial scripts into a comprehensive Software as a Service (SaaS) solution accessible to clients via Elastic Kubernetes Service (EKS) on AWS.\n\n\n Offered technical consulting services to a startup specializing in cognitive and educational technologies, translating academic research in cognitive neuroscience and developmental psychology into actionable solutions, while also advising on machine learning implementations.\n\n\n Collaborated closely with analysts across departments to design, build, and deploy various initiatives within the data platform, including the development, deployment, and maintenance of data services using R and PostgreSQL. Additionally, implemented best practices for continuous process automation, resulting in significant time savings for month-end processing.\n\n\n \n\n\n\n\n Conducted in-depth data analysis to classify customers using Bayesian inference, revealing distinct segments and patterns for data-driven decision-making and targeted strategies.\n\n\n Designed and implemented Apache NiFi ETL for efficient data processing and orchestration, contributing to streamlined data engineering workflows.\n\n\n Developed new internal tools for data analysts.\n\n\n \n\n\n\n\n Led the development of the data science infrastructure, creating an environment tailored for cutting-edge research and innovation.\n\n\n Developed and implemented complex statistical models in R to detect fraudulent transactions.\n\n\n Designed and maintained a data visualization dashboard in R Shiny, which allowed for easy monitoring of key performance indicators.\n\n\n \n\n\n\n\n Conducted lectures on statistics for the graduate program.\n\n\n Mentored and supervised graduate students in their statistical research projects, nurturing their analytical skills and research capabilities.\n\n\n Created and shared freely available data workshops in R and Python.\n\n\n\n\n\n\n\n Led an independent research project in Pr. Wraga’s visual cognition group.\n\n\n Designed and collected data for a cognitive neuroscience experiment.\n\n\n\n\n\n\n\n Led an independent research project as part of Dr. Burra’s attentional capture group.\n\n\n Conducted signal processing of EEG data."
  },
  {
    "objectID": "vitae.html#fa-cube-open-source-contributions",
    "href": "vitae.html#fa-cube-open-source-contributions",
    "title": "Full CV",
    "section": "",
    "text": "echarts4r\n\nR, JavaScript - 2023 - Present\nCollaborated on the development of echarts4r, a R package that expands the capabilities of R-based interactive visualizations with a powerful rendering engine, while enhancing flexibility and ease of use.\n\n\n\n\n Firebase\n\nR, JavaScript - 2023 - Present\nContributed to the firebase integration package for R, empowering the Shiny user community by enabling user authentication and secure file storage through Firebase Storage.\n\n\n\n\n DbVieweR\n\nR, SQL - 2022 - Present\nCreated a shiny app simulating a database management system featuring functions like login authentication, save/create/delete tables, add/rename columns, using either a PostgreSQL or SQLite back-end. DbVieweR\n\n\n\n\n\n\n\n reprtree\n\nR - 2022\nIntegrated the caret ensemble for reprtree (implementation of representative trees from ensembles of tree-based machines).\n\n\n\n\n hBayesDM\n\nSTAN, R, Python - 2021\nCollaborated on the Hierarchical Bayesian modeling of Decision-Making tasks library. Built Q-learning algorithm for probabilistic selection task. hBayesDM\n\n\n\n\n 3dLMEr\n\nBASH, R - 2020\nCollaborated on the AFNI’s functions for 3Dimensional Linear Mixed-Effects Regression. Fixed residuals output image by adding bottom tolerance. 3dLMEr"
  },
  {
    "objectID": "vitae.html#fa-language-languages",
    "href": "vitae.html#fa-language-languages",
    "title": "Full CV",
    "section": "",
    "text": "French (Mother Tongue)\n Spanish (Mother Tongue)\n English (Fluent)\n German (Basic)\n Italian (Basic)"
  },
  {
    "objectID": "vitae.html#fa-trophy-accomplishments",
    "href": "vitae.html#fa-trophy-accomplishments",
    "title": "Full CV",
    "section": "",
    "text": "Top 2% on Stack Overflow in 2024\n Top 25% on GitHub in 2023\n Global Fellow scholarship recipient in 2017"
  },
  {
    "objectID": "vitae.html#fa-user-extracurricular-activities",
    "href": "vitae.html#fa-user-extracurricular-activities",
    "title": "Full CV",
    "section": "",
    "text": "Contributing to We Data’s mission by facilitating workshops, providing statistics tutorials, and participating in coding demonstrations.\n Organizing R-Lunches at UniGe.\n Co-founder of Go-Fast, a socially responsible Bike Messenger cooperative in Geneva.\n Co-president of La Rustine, a non-profit organization promoting non-motorized mobility and self-sustainability in Switzerland."
  },
  {
    "objectID": "vitae.html#fa-lightbulb-interests",
    "href": "vitae.html#fa-lightbulb-interests",
    "title": "Full CV",
    "section": "",
    "text": "Artificial Intelligence\n Machine Learning\n Bayesian Statistics\n Natural Language Processing\n Data Visualization\n Ethics in Technology\n Data Privacy\n Data Engineering\n Cybersecurity\n Data Journalism\n\n  References Available upon request."
  },
  {
    "objectID": "index.html#fa-hand-peace-hi-im-david.-fa-hand-peace-im-a-data-scientist-r-developer-always-looking-for-a-cool-open-source-project",
    "href": "index.html#fa-hand-peace-hi-im-david.-fa-hand-peace-im-a-data-scientist-r-developer-always-looking-for-a-cool-open-source-project",
    "title": "David Munoz Tord",
    "section": " Hi, I’m David.   I’m a Data Scientist / R Developer always looking for a cool open-source project ! ",
    "text": "Hi, I’m David.   I’m a Data Scientist / R Developer always looking for a cool open-source project !"
  },
  {
    "objectID": "services/mining/index.html",
    "href": "services/mining/index.html",
    "title": "David Munoz Tord",
    "section": "",
    "text": "Data exploration, application of statistical methods, reproducible data analysis.\n Crunch the data to get answer to your question. Give insight to the information.\nI can help you to:\n\n Exploratory analysis of a dataset.\n Creation of clean and reproducible reports using Rmardown and Shiny.\n Application of statistical methods on your dataset.\n Creation of custom scripts for analyzing/ingesting your data automatically\n\n\n\n\n\n\n I’m the author of several scientific publications where I was in charge to explore and understand complex dataset in order to answer scientific questions.\n I built machine learning pipelines to implement predictive models to detect fraud in clients behavior and analyze it..\n - Designed and implemented Apache NiFi ETL for efficient data processing and orchestration, contributing to streamlined data workflows.\n\n\n\n\n\nIf you’re interested in learning more about how I can assist with your project, feel free to reach out at david.munoztord@mailbox.org."
  },
  {
    "objectID": "services/mining/index.html#fa-search-data-science-and-analysis",
    "href": "services/mining/index.html#fa-search-data-science-and-analysis",
    "title": "David Munoz Tord",
    "section": "",
    "text": "Data exploration, application of statistical methods, reproducible data analysis.\n Crunch the data to get answer to your question. Give insight to the information.\nI can help you to:\n\n Exploratory analysis of a dataset.\n Creation of clean and reproducible reports using Rmardown and Shiny.\n Application of statistical methods on your dataset.\n Creation of custom scripts for analyzing/ingesting your data automatically\n\n\n\n\n\n\n I’m the author of several scientific publications where I was in charge to explore and understand complex dataset in order to answer scientific questions.\n I built machine learning pipelines to implement predictive models to detect fraud in clients behavior and analyze it..\n - Designed and implemented Apache NiFi ETL for efficient data processing and orchestration, contributing to streamlined data workflows.\n\n\n\n\n\nIf you’re interested in learning more about how I can assist with your project, feel free to reach out at david.munoztord@mailbox.org."
  },
  {
    "objectID": "services/data_engineering/index.html",
    "href": "services/data_engineering/index.html",
    "title": "David Munoz Tord",
    "section": "",
    "text": "A data project always start with a data engineering step. You need to harvest data and store it in an adequate format to be able to use it. Let me help you with it !\nI can help you to:\n\n Harvest data from various sources, including APIs, SQL databases, or complex Excel spreadsheets.\n Reformat and reshape data to facilitate further analysis.\n Clean datasets to remove outliers and aberrant data points.\n Develop reproducible data preparation workflows.\n Automate the creation of data-related reports.\n\n\n\n\n\n\n Led development and launch of a collaborative project with EPFL, transitioning scripts into a Software as a Service (SaaS) solution on AWS.\n Provided technical consulting to a startup, translating academic research into actionable solutions and advising on machine learning.\n Collaborated across departments to design and deploy data platform initiatives, implementing automation for time savings.\n\n\n\n\n\nIf you’re interested in learning more about how I can assist with your project, feel free to reach out at david.munoztord@mailbox.org."
  },
  {
    "objectID": "services/data_engineering/index.html#fa-cog-data-engineering",
    "href": "services/data_engineering/index.html#fa-cog-data-engineering",
    "title": "David Munoz Tord",
    "section": "",
    "text": "A data project always start with a data engineering step. You need to harvest data and store it in an adequate format to be able to use it. Let me help you with it !\nI can help you to:\n\n Harvest data from various sources, including APIs, SQL databases, or complex Excel spreadsheets.\n Reformat and reshape data to facilitate further analysis.\n Clean datasets to remove outliers and aberrant data points.\n Develop reproducible data preparation workflows.\n Automate the creation of data-related reports.\n\n\n\n\n\n\n Led development and launch of a collaborative project with EPFL, transitioning scripts into a Software as a Service (SaaS) solution on AWS.\n Provided technical consulting to a startup, translating academic research into actionable solutions and advising on machine learning.\n Collaborated across departments to design and deploy data platform initiatives, implementing automation for time savings.\n\n\n\n\n\nIf you’re interested in learning more about how I can assist with your project, feel free to reach out at david.munoztord@mailbox.org."
  },
  {
    "objectID": "services/dataviz/index.html",
    "href": "services/dataviz/index.html",
    "title": "David Munoz Tord",
    "section": "",
    "text": "Creation of static and interactive dataviz, review of scientific figures.\n\nI’m an expert in the field of dataviz. I’ve created several tutorials and given talks on this topic.\nI can help you to:\n\n Creation and review of graphs for scientific publication.\n Development of data application using R and Shiny.\n Creation of custom data visualization for the web.\n Dashboard creation for real time data analysis.\n Visualization of geospatial data.\n\n\n\n\n\n\n I maintain and develop echarts4r, a declarative framework for rapid construction of Web-based data visualization.\n I reviewed and improved scientific figures for research publications, ensuring clarity and accuracy in data representation.\n I conducted several workshops on data visualization techniques, covering topics such as chart types, color theory, and storytelling with data.\n\n\n\n\n\nIf you’re interested in learning more about how I can assist with your project, feel free to reach out at david.munoztord@mailbox.org."
  },
  {
    "objectID": "services/dataviz/index.html#fa-chart-bar-data-visualization",
    "href": "services/dataviz/index.html#fa-chart-bar-data-visualization",
    "title": "David Munoz Tord",
    "section": "",
    "text": "Creation of static and interactive dataviz, review of scientific figures.\n\nI’m an expert in the field of dataviz. I’ve created several tutorials and given talks on this topic.\nI can help you to:\n\n Creation and review of graphs for scientific publication.\n Development of data application using R and Shiny.\n Creation of custom data visualization for the web.\n Dashboard creation for real time data analysis.\n Visualization of geospatial data.\n\n\n\n\n\n\n I maintain and develop echarts4r, a declarative framework for rapid construction of Web-based data visualization.\n I reviewed and improved scientific figures for research publications, ensuring clarity and accuracy in data representation.\n I conducted several workshops on data visualization techniques, covering topics such as chart types, color theory, and storytelling with data.\n\n\n\n\n\nIf you’re interested in learning more about how I can assist with your project, feel free to reach out at david.munoztord@mailbox.org."
  },
  {
    "objectID": "services/teaching/index.html",
    "href": "services/teaching/index.html",
    "title": "David Munoz Tord",
    "section": "",
    "text": "Short talks or multi-day courses on dataviz, R, ggplot2, data analytics and more.\n\nI have a passion for teaching and have conducted numerous workshops and training sessions on various topics related to data science and analytics.\nI can help you to:\n\n Conducting short talks or multi-day courses on data visualization, R programming, ggplot2, reproducible research, bayesian statistics, and data analytics.\n Providing customized training sessions tailored to your specific needs and objectives.\n\n\n\n\n\n\n I delivered a series of short talks on data visualization techniques for undergraduate students, covering fundamental principles and practical tips for creating effective visualizations.\n I taught a multi-day course on R programming for beginners, covering topics such as data manipulation, visualization, and basic statistical analysis.\n I organized and facilitated a workshop on ggplot2, a popular data visualization package in R, demonstrating how to create customized plots and advanced visualizations.\n I provided training sessions on data analytics tools and techniques to professionals in the industry, helping them develop skills in data exploration, modeling, and interpretation.\n Additionally, I have contributed to educational materials, such as this repository, where I share resources and tutorials for learning data science concepts and tools.\n I have also been a guest on several podcasts, discussing topics related to data science, analytics, and visualization.\n\n\n\n\n\nTell me more about your training needs at david.munoztord@mailbox.org to see if we can work together."
  },
  {
    "objectID": "services/teaching/index.html#fa-university-teaching-training",
    "href": "services/teaching/index.html#fa-university-teaching-training",
    "title": "David Munoz Tord",
    "section": "",
    "text": "Short talks or multi-day courses on dataviz, R, ggplot2, data analytics and more.\n\nI have a passion for teaching and have conducted numerous workshops and training sessions on various topics related to data science and analytics.\nI can help you to:\n\n Conducting short talks or multi-day courses on data visualization, R programming, ggplot2, reproducible research, bayesian statistics, and data analytics.\n Providing customized training sessions tailored to your specific needs and objectives.\n\n\n\n\n\n\n I delivered a series of short talks on data visualization techniques for undergraduate students, covering fundamental principles and practical tips for creating effective visualizations.\n I taught a multi-day course on R programming for beginners, covering topics such as data manipulation, visualization, and basic statistical analysis.\n I organized and facilitated a workshop on ggplot2, a popular data visualization package in R, demonstrating how to create customized plots and advanced visualizations.\n I provided training sessions on data analytics tools and techniques to professionals in the industry, helping them develop skills in data exploration, modeling, and interpretation.\n Additionally, I have contributed to educational materials, such as this repository, where I share resources and tutorials for learning data science concepts and tools.\n I have also been a guest on several podcasts, discussing topics related to data science, analytics, and visualization.\n\n\n\n\n\nTell me more about your training needs at david.munoztord@mailbox.org to see if we can work together."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "tl;dr\n\nPassionated about code  Bayesian stats  DevOps  Neurosciences  machine learning  beer  wine  coffee  travel  and striving for balance  I love abstract and conceptual thinking and am always trying to learn something new"
  },
  {
    "objectID": "blog/Live/index.html",
    "href": "blog/Live/index.html",
    "title": "We-Data Live on YouTube",
    "section": "",
    "text": "By David Munoz Tord, Fabrice Hategekimana and Vestin Hategekimana\nLive of December 29 edited in which we present in more detail WeData, its functioning and its future.\nNote: video in french, ask in comments for subtitle in your language\nVideo link"
  },
  {
    "objectID": "blog/llm2/index.html",
    "href": "blog/llm2/index.html",
    "title": "Your first chat bot with python!",
    "section": "",
    "text": "By David Munoz Tord\nGoal: Learn about language models and familiarize yourself with some of the basic functions of the {languagemodels} to create your own chat bot.\n{languagemodels} is a python module designed to be as simple as possible for learners and educators exploring how large language models intersect with modern software development. The interfaces to this package are all simple functions using standard types. The complexity of large language models is hidden from view while providing free local inference using light-weight, open models. All included models are free for educational use, no API keys are required, and all inference is performed locally by default.\nRead more about it\n\nimport languagemodels as lm\n\n\nlm.do(\"What color is the sky?\")\n\n'The color of the sky is blue.'\n\n\nFetching 6 files:   0%|          | 0/6 [00:00&lt;?, ?it/s]\nFetching 6 files: 100%|##########| 6/6 [00:00&lt;00:00, 8053.06it/s]\n\n\n\nTo easy, let’s try something a bit harder\n\nlm.do(\"If I have 7 apples then eat 5, how many apples do I have?\")\n\n'You have 8 apples.'\n\n\nAouch…\nIndeed the model performance is quite low because the models used by this package are 1000x smaller than the largest models in use today. They are useful as learning tools, but if you are expecting ChatGPT or similar performance, you will be very disappointed…\nThe base model should work on any system with 512MB of memory, but this memory limit can be increased. Setting this value higher will require more memory and generate results more slowly, but the results should be superior.\n\n#lm.set_max_ram('4gb')\n\n\nlm.do(\"If I have 7 apples then eat 5, how many apples do I have?\")\n\n'You have 8 apples.'\n\n\nYeah, here we go little (4gb) buddy!\n\nNow that we got the basics, let’s play with it! You can change the prompt like such\n\nlm.chat('''\n     System: Respond as a physics professor.\n\n     User: What is relativity?\n\n     Assistant:\n     ''')\n\n'Relativity is the theory of relativity, which describes how time and space are relative to each other.'\n\n\n\n\nlm.complete(\"She hid in her room until\")\n\n' the night sky turned blue.'\n\n\n\n\nlm.get_wiki(\"Physics\")\n\n'Physics is the natural science of matter, involving the study of matter, its fundamental constituents, its motion and behavior through space and time, and the related entities of energy and force. Physics is one of the most fundamental scientific disciplines, with its main goal being to understand how the universe behaves. A scientist who specializes in the field of physics is called a physicist.\\n\\nPhysics is one of the oldest academic disciplines and, through its inclusion of astronomy, perhaps the oldest. Over much of the past two millennia, physics, chemistry, biology, and certain branches of mathematics were a part of natural philosophy, but during the Scientific Revolution in the 17th century these natural sciences emerged as unique research endeavors in their own right. Physics intersects with many interdisciplinary areas of research, such as biophysics and quantum chemistry, and the boundaries of physics are not rigidly defined. New ideas in physics often explain the fundamental mechanisms studied by other sciences and suggest new avenues of research in these and other academic disciplines such as mathematics and philosophy.\\n\\nAdvances in physics often enable new technologies. For example, advances in the understanding of electromagnetism, solid-state physics, and nuclear physics led directly to the development of new products that have dramatically transformed modern-day society, such as television, computers, domestic appliances, and nuclear weapons; advances in thermodynamics led to the development of industrialization; and advances in mechanics inspired the development of calculus.'"
  },
  {
    "objectID": "blog/Data_explor_Fundamentals/index.html",
    "href": "blog/Data_explor_Fundamentals/index.html",
    "title": "Data Exploration with R",
    "section": "",
    "text": "By David Munoz Tord\nGoal: Learn about data exploration and familiarize yourself with some of the basic functions of the tidyverse.\nOpen it full\nNote: All in english"
  },
  {
    "objectID": "blog/Data_Viz_Fundamentals/index.html",
    "href": "blog/Data_Viz_Fundamentals/index.html",
    "title": "Data Viz Fundamentals with R",
    "section": "",
    "text": "By David Munoz Tord\nGoal: Go over the basics of data visualization with R and learn more advanced concepts using the ggplot package.\nNote: All is in english\nOpen it full"
  },
  {
    "objectID": "blog/Data_manip_Fundamental/index.html",
    "href": "blog/Data_manip_Fundamental/index.html",
    "title": "Data Manipulation with R",
    "section": "",
    "text": "By David Munoz Tord\nGoal: Learn more about data manipulation: how to pivot, join and filter data using {dplyr} and {tidyr} packages.\nOpen it full\nNote: All in english"
  },
  {
    "objectID": "blog/R-Lunches/index.html",
    "href": "blog/R-Lunches/index.html",
    "title": "R Lunches in university of Geneva",
    "section": "",
    "text": "By David Munoz Tord\nR lunches are multidisciplinary meetings on R at UniMail.\nWe finished this semester R Lunches but you can still find the video links if you missed one!\nRead more about it"
  },
  {
    "objectID": "services.html",
    "href": "services.html",
    "title": "Services",
    "section": "",
    "text": "Services\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n Data Science and Analysis\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n Data Engineering\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n Data Visualization\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\n Teaching & Training\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  }
]